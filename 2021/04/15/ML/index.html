<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/epic-180x180">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/epic-32x32">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="More">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning">
<meta property="og:url" content="http://example.com/2021/04/15/ML/index.html">
<meta property="og:site_name" content="@Xinjian Pan">
<meta property="og:description" content="More">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/pca_mim_distance.JPG">
<meta property="og:image" content="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/pca_var.JPG">
<meta property="og:image" content="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/pca_1.JPG">
<meta property="og:image" content="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/pca_2.JPG">
<meta property="og:image" content="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/image-20210416140003841.png">
<meta property="og:image" content="https://images0.cnblogs.com/blog/670089/201501/081543500006068.png">
<meta property="og:image" content="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/sigmoid.JPG">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=p_k+=+(%5Cfrac+%7B1%7D%7B2%7D,%5Cfrac+%7B1%7D%7B4%7D,%5Cfrac+%7B1%7D%7B8%7D,%5Cfrac+%7B1%7D%7B8%7D)">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=q_k+=+(%5Cfrac+%7B1%7D%7B4%7D,%5Cfrac+%7B1%7D%7B4%7D,%5Cfrac+%7B1%7D%7B4%7D,%5Cfrac+%7B1%7D%7B4%7D)">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7B2%7D+*+%5Clog_2+4+++%5Cfrac%7B1%7D%7B4%7D+*+%5Clog_2+4+++%5Cfrac%7B1%7D%7B8%7D+*+%5Clog_2+4+++%5Cfrac%7B1%7D%7B8%7D+*+%5Clog_2+4+=+2">
<meta property="og:image" content="https://habrastorage.org/files/010/ded/77e/010ded77e8d0454b99f0cafd3d962613.png">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/6/6b/Roccurves.png">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-a2a73f43adcbb0bf4b9bae19b9495f81_1440w.png">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=S_%7Bj%7D+">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/27695029-4f327793a9d758b6.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/27695029-6c25b23439b92b7a.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20181102194631741.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA0MjAyODM=,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/b/ba/Normalverteilung.PNG">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Normal_Distribution_CDF.svg/1920px-Normal_Distribution_CDF.svg.png">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Discrete_probability_distrib.svg/1920px-Discrete_probability_distrib.svg.png">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Poisson_pmf.svg/488px-Poisson_pmf.svg.png">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Poisson_cdf.svg/1024px-Poisson_cdf.svg.png">
<meta property="og:image" content="https://www.qiujiawei.com/images/2016.8/1.png">
<meta property="og:image" content="https://pic1.zhimg.com/50/v2-5eb5e035330831cd01d8fbea8d5b51e7_720w.jpg?source=1940ef5c">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-5eb5e035330831cd01d8fbea8d5b51e7_1440w.jpg?source=1940ef5c">
<meta property="og:image" content="https://pica.zhimg.com/50/v2-b082814755a62fcf676f3d08c70d2d0d_720w.jpg?source=1940ef5c">
<meta property="og:image" content="https://pica.zhimg.com/80/v2-b082814755a62fcf676f3d08c70d2d0d_1440w.jpg?source=1940ef5c">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5CSigma+P(x,+y)+=+1">
<meta property="og:image" content="https://pic2.zhimg.com/50/v2-11f8a39d629e2649146bf12794fe310c_720w.jpg?source=1940ef5c">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-11f8a39d629e2649146bf12794fe310c_1440w.jpg?source=1940ef5c">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Csum_%7By%7D%7BP(y+%7C+x)%7D+=+1+">
<meta property="og:image" content="http://latex.codecogs.com/gif.latex?f%5Cleft&space;(&space;x&space;%5Cright&space;)=f%5Cleft&space;(&space;x_k&space;%5Cright&space;)+%7Bf%7D%27%5Cleft&space;(&space;x_k&space;%5Cright&space;)%5Cleft&space;(&space;x-x_k&space;%5Cright&space;)+%5Cfrac%7B1%7D%7B2%7D%7Bf%7D%27%27%5Cleft&space;(&space;x_k&space;%5Cright&space;)%5Cleft&space;(&space;x-x_k&space;%5Cright&space;)%5E2">
<meta property="og:image" content="http://latex.codecogs.com/gif.latex?%7Bf%7D%27%5Cleft&space;(&space;x_k&space;%5Cright&space;)+%7Bf%7D%27%27%5Cleft&space;(&space;x_k&space;%5Cright&space;)%5Cleft&space;(&space;x-x_k&space;%5Cright&space;)=0">
<meta property="og:image" content="http://latex.codecogs.com/gif.latex?x=x_k-%5Cfrac%7B%7Bf%7D%27%5Cleft&space;(&space;x_k&space;%5Cright&space;)%7D%7B%7Bf%7D%27%27%5Cleft&space;(&space;x_k&space;%5Cright&space;)%7D">
<meta property="og:image" content="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/model.JPG">
<meta property="og:image" content="https://pica.zhimg.com/v2-a026e24156e13a1d14c43df26b9bd2a4_r.jpg?source=1940ef5c">
<meta property="og:image" content="https://pica.zhimg.com/v2-f6edae58134c5a26687c3883af48d5d5_r.jpg?source=1940ef5c">
<meta property="og:image" content="https://pic3.zhimg.com/v2-3aaa69f70754c469bca5c8e4c3e161db_r.jpg?source=1940ef5c">
<meta property="og:image" content="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/MSE.JPG">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/9c16e9482a860b7f354bcd8a4d5c418e.png">
<meta property="og:image" content="https://img-blog.csdn.net/20160611221836609?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://img-blog.csdn.net/20160611221842349?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://img-blog.csdn.net/20160611221847422?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://img-blog.csdn.net/20160611221851021?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://img-blog.csdn.net/20160611222004158?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://img-blog.csdn.net/20160611211339152?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7DGini(D)&=%5Csum_%7Bi=1%7D%5E%7Bn%7D%7Bp(x_i)*(1-p(x_i))%7D+%5C%5C&=1-%5Csum_%7Bi=1%7D%5E%7Bn%7D%7B%7Bp(x_i)%7D%5E2%7D%5Cend%7Baligned%7D++%5C%5C">
<meta property="og:image" content="https://wikimedia.org/api/rest_v1/media/math/render/svg/2fe7849758309b19fa49cad2f5e214fb4fbb8044">
<meta property="og:image" content="https://wikimedia.org/api/rest_v1/media/math/render/svg/e76702c87ce1c681ed1da8213125963524ca0ee6">
<meta property="og:image" content="https://wikimedia.org/api/rest_v1/media/math/render/svg/5decdfc7edb14bc3f4dd541d39559ea9a3088f61">
<meta property="og:image" content="https://github.com/PPPPan/PPPPan.github.io/blob/master/images/sne_1.JPG?raw=true">
<meta property="og:image" content="https://github.com/PPPPan/PPPPan.github.io/blob/master/images/sne2.JPG?raw=true">
<meta property="og:image" content="https://github.com/PPPPan/PPPPan.github.io/blob/master/images/sne3.JPG?raw=true">
<meta property="og:image" content="https://github.com/PPPPan/PPPPan.github.io/blob/master/images/sne4.JPG?raw=true">
<meta property="og:image" content="https://github.com/PPPPan/PPPPan.github.io/blob/master/images/sne6.JPG?raw=true">
<meta property="og:image" content="https://github.com/PPPPan/PPPPan.github.io/blob/master/images/sne5.JPG?raw=true">
<meta property="article:published_time" content="2021-04-15T18:07:25.834Z">
<meta property="article:modified_time" content="2022-05-02T18:21:27.346Z">
<meta property="article:author" content="Xinjian Pan  ğŸ‘¨ğŸ»â€ğŸ’»">
<meta property="article:tag" content="ML">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/pca_mim_distance.JPG">

<link rel="canonical" href="http://example.com/2021/04/15/ML/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Machine Learning | @Xinjian Pan</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">@Xinjian Pan</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about-me">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About Me</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">16</span></a>

  </li>
        <li class="menu-item menu-item-cv">

    <a href="/CV/" rel="section"><i class="fa fa-archive fa-fw"></i>CV</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/04/15/ML/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Xinjian Pan  ğŸ‘¨ğŸ»â€ğŸ’»">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="@Xinjian Pan">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Machine Learning
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-15 20:07:25" itemprop="dateCreated datePublished" datetime="2021-04-15T20:07:25+02:00">2021-04-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-05-02 20:21:27" itemprop="dateModified" datetime="2022-05-02T20:21:27+02:00">2022-05-02</time>
              </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <div class="post-description">More</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <span id="more"></span>

<!-- toc -->

<ul>
<li><a href="#%E5%90%91%E9%87%8F%E5%92%8C%E7%9F%A9%E9%98%B5">å‘é‡å’ŒçŸ©é˜µ</a></li>
<li><a href="#%E5%90%91%E9%87%8F%E7%9A%84%E8%8C%83%E6%95%B0norm">å‘é‡çš„èŒƒæ•°(norm)</a></li>
<li><a href="#%E9%80%86%E7%9F%A9%E9%98%B5matrix-inversion">é€†çŸ©é˜µ(matrix inversion)</a></li>
<li><a href="#%E5%8D%95%E4%BD%8D%E5%90%91%E9%87%8F">å•ä½å‘é‡</a></li>
<li><a href="#%E6%AD%A3%E4%BA%A4%E7%9F%A9%E9%98%B5orthogonal-matrix">æ­£äº¤çŸ©é˜µï¼ˆorthogonal matrixï¼‰</a></li>
<li><a href="#%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A3eigendecomposition">ç‰¹å¾åˆ†è§£ï¼ˆeigendecomposition)</a></li>
<li><a href="#%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3singular-value-decomposition-svd">å¥‡å¼‚å€¼åˆ†è§£ï¼ˆsingular value decomposition, SVD)</a></li>
<li><a href="#%E8%BF%B9%E8%BF%90%E7%AE%97">è¿¹è¿ç®—</a></li>
<li><a href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90principal-components-analysis-pca">ä¸»æˆåˆ†åˆ†æï¼ˆprincipal components analysis, PCAï¼‰</a></li>
<li><a href="#%E6%A6%82%E7%8E%87%E8%AE%BA">æ¦‚ç‡è®º</a><ul>
<li><a href="#%E4%BF%A1%E4%BB%BB%E5%BA%A6degree-of-belief">ä¿¡ä»»åº¦(degree of belief):</a></li>
<li><a href="#%E5%BD%92%E4%B8%80%E5%8C%96normalized">å½’ä¸€åŒ–ï¼ˆnormalizedï¼‰</a></li>
<li><a href="#%E7%A6%BB%E6%95%A3%E5%9D%87%E5%8C%80%E5%88%86%E5%B8%83uniform-distribution">ç¦»æ•£å‡åŒ€åˆ†å¸ƒï¼ˆuniform distributionï¼‰:</a></li>
<li><a href="#%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0probability-density-function">æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆprobability density function):</a><ul>
<li><a href="#%E8%BF%9E%E7%BB%AD%E5%9D%87%E5%8C%80%E5%88%86%E5%B8%83">è¿ç»­å‡åŒ€åˆ†å¸ƒ:</a></li>
</ul>
</li>
<li><a href="#%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99chain-rule">é“¾å¼æ³•åˆ™ï¼ˆchain ruleï¼‰:</a></li>
<li><a href="#%E7%8B%AC%E7%AB%8B%E6%80%A7independent">ç‹¬ç«‹æ€§ï¼ˆindependentï¼‰:</a></li>
<li><a href="#%E6%9C%9F%E6%9C%9Bexpectation">æœŸæœ›ï¼ˆexpectationï¼‰:</a></li>
<li><a href="#%E6%96%B9%E5%B7%AEvariance">æ–¹å·®ï¼ˆvarianceï¼‰:</a></li>
<li><a href="#%E5%8D%8F%E6%96%B9%E5%B7%AEcovariance">åæ–¹å·®ï¼ˆcovarianceï¼‰:</a></li>
<li><a href="#%E5%B8%B8%E7%94%A8%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83">å¸¸ç”¨æ¦‚ç‡åˆ†å¸ƒ</a></li>
</ul>
</li>
<li><a href="#%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97">æ•°å€¼è®¡ç®—</a><ul>
<li><a href="#jacobian%E7%9F%A9%E9%98%B5">JacobiançŸ©é˜µ</a></li>
</ul>
</li>
<li><a href="#hessian-%E7%9F%A9%E9%98%B5">Hessian çŸ©é˜µ</a><ul>
<li><a href="#karushkuhntuckerkkt">Karushâ€“Kuhnâ€“Tuckerï¼ˆKKTï¼‰</a></li>
</ul>
</li>
<li><a href="#%E8%B7%9D%E7%A6%BB%E9%80%89%E6%8B%A9%E5%85%AC%E5%BC%8F">è·ç¦»é€‰æ‹©å…¬å¼</a><ul>
<li><a href="#%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E8%B7%9D%E7%A6%BB">æ¬§å‡ é‡Œå¾—è·ç¦»</a></li>
<li><a href="#%E6%9B%BC%E5%93%88%E9%A1%BF%E8%B7%9D%E7%A6%BB">æ›¼å“ˆé¡¿è·ç¦»</a></li>
</ul>
</li>
<li><a href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86">è´å¶æ–¯å®šç†</a></li>
<li><a href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AFnaive-bayesian-algorithm">æœ´ç´ è´å¶æ–¯(Naive Bayesian algorithm)</a><ul>
<li><a href="#%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%B9%B3%E6%BB%91%E5%A4%84%E7%90%86laplace-smoothing">æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘å¤„ç†(Laplace Smoothing)</a></li>
</ul>
</li>
<li><a href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0loss-function%E6%88%96%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0cost-function">æŸå¤±å‡½æ•°(loss function)æˆ–ä»£ä»·å‡½æ•°(cost function)</a><ul>
<li><a href="#%E5%B9%B3%E6%96%B9%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0quadratic-loss-function">å¹³æ–¹æŸå¤±å‡½æ•°(quadratic loss function)</a></li>
<li><a href="#%E7%BB%8F%E9%AA%8C%E6%8D%9F%E5%A4%B1empirical-loss-r_emp">ç»éªŒæŸå¤±(empirical loss) $R_{emp}$</a></li>
<li><a href="#regression-loss">Regression Loss</a><ul>
<li><a href="#l_1-loss-laplace-loss-absolute-loss">$l_1$ Loss &#x2F; Laplace Loss &#x2F; Absolute Loss</a></li>
<li><a href="#l_2-loss-square-loss">$l_2$ Loss &#x2F; Square Loss</a></li>
<li><a href="#huber-loss">Huber Loss</a></li>
</ul>
</li>
<li><a href="#classification-loss">Classification Loss</a><ul>
<li><a href="#margin">Margin</a></li>
<li><a href="#zero-one">Zero-one</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#gramm%E7%9F%A9%E9%98%B5">GrammçŸ©é˜µ</a></li>
<li><a href="#mercers-theorem">Mercerâ€™s Theorem</a></li>
<li><a href="#kernel-trick">Kernel Trick</a></li>
<li><a href="#%E6%9D%B0%E6%A3%AE%E4%B8%8D%E7%AD%89%E5%BC%8Fjensens-inequality">æ°æ£®ä¸ç­‰å¼(Jensenâ€™s inequality)</a></li>
<li><a href="#%E5%87%B8%E5%87%BD%E6%95%B0">å‡¸å‡½æ•°</a></li>
<li><a href="#weak-max-min-inequality">Weak Max-Min Inequality</a></li>
<li><a href="#%E6%9D%BE%E5%BC%9B%E4%BA%92%E8%A1%A5complementary-slackness">æ¾å¼›äº’è¡¥ï¼ˆComplementary slacknessï¼‰</a></li>
<li><a href="#%E4%B8%A4%E5%B9%B3%E8%A1%8C%E7%BA%BF%E8%B7%9D%E7%A6%BB%E5%85%AC%E5%BC%8F">ä¸¤å¹³è¡Œçº¿è·ç¦»å…¬å¼</a></li>
<li><a href="#pdfprobability-density-function">PDF(Probability density function)</a></li>
<li><a href="#cdfcumulative-distribution-function">CDF(Cumulative distribution function)</a></li>
<li><a href="#pmfprobability-mass-function">PMF(probability mass function)</a></li>
<li><a href="#%E6%B3%8A%E6%9D%BE%E5%88%86%E5%B8%83poisson-distribution">æ³Šæ¾åˆ†å¸ƒ(Poisson distribution)</a></li>
<li><a href="#variance">Variance</a></li>
<li><a href="#%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83%E5%92%8C%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83">ä¼¯åŠªåˆ©åˆ†å¸ƒå’ŒäºŒé¡¹åˆ†å¸ƒ</a></li>
<li><a href="#z%E5%88%86%E5%B8%83%E5%92%8Ct%E5%88%86%E5%B8%83">Zåˆ†å¸ƒå’ŒTåˆ†å¸ƒ</a></li>
<li><a href="#%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E7%A7%AF%E5%88%86">è’™ç‰¹å¡æ´›ç§¯åˆ†</a></li>
<li><a href="#%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B">åˆ¤åˆ«æ¨¡å‹å’Œç”Ÿæˆæ¨¡å‹</a></li>
<li><a href="#%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1mle">æå¤§ä¼¼ç„¶ä¼°è®¡(MLE)</a></li>
<li><a href="#%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87-map">æœ€å¤§åéªŒæ¦‚ç‡ (MAP)</a></li>
<li><a href="#%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80">æ³°å‹’å±•å¼€</a></li>
<li><a href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95">æ¢¯åº¦ä¸‹é™æ³•</a></li>
<li><a href="#%E7%89%9B%E9%A1%BF%E6%B3%95">ç‰›é¡¿æ³•</a></li>
</ul>
<ul>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80">æœºå™¨å­¦ä¹ åŸºç¡€</a><ul>
<li><a href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95unsupervised-learning-algorithm">æ— ç›‘ç£å­¦ä¹ ç®—æ³•ï¼ˆunsupervised learning algorithmï¼‰</a></li>
<li><a href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95supervised-learning-algorithm">ç›‘ç£å­¦ä¹ ç®—æ³•ï¼ˆsupervised learning algorithm)</a></li>
<li><a href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0rein-forcement-learning%E7%AE%97%E6%B3%95">å¼ºåŒ–å­¦ä¹ ï¼ˆrein-forcement learningï¼‰ç®—æ³•</a></li>
<li><a href="#%E8%AE%BE%E8%AE%A1%E7%9F%A9%E9%98%B5design-matrix">è®¾è®¡çŸ©é˜µï¼ˆdesign matrixï¼‰</a></li>
<li><a href="#%E8%AE%AD%E7%BB%83%E8%AF%AF%E5%B7%AEtraining-error">è®­ç»ƒè¯¯å·®ï¼ˆtraining errorï¼‰</a></li>
<li><a href="#%E6%B5%8B%E8%AF%95%E8%AF%AF%E5%B7%AEtest-error">æµ‹è¯•è¯¯å·®ï¼ˆtest errorï¼‰</a></li>
<li><a href="#%E5%A5%A5%E5%8D%A1%E5%A7%86%E5%89%83%E5%88%80-occams-razor">å¥¥å¡å§†å‰ƒåˆ€ Occamâ€™s Razor</a></li>
<li><a href="#vapnik-chervonenkis-%E7%BB%B4%E5%BA%A6">Vapnik-Chervonenkis ç»´åº¦</a></li>
<li><a href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E8%AF%AF%E5%B7%AEbayes-error">è´å¶æ–¯è¯¯å·®ï¼ˆBayes errorï¼‰</a></li>
<li><a href="#%E6%B2%A1%E6%9C%89%E5%85%8D%E8%B4%B9%E5%8D%88%E9%A4%90%E5%AE%9A%E7%90%86no-freelunch-theorem">æ²¡æœ‰å…è´¹åˆé¤å®šç†ï¼ˆno freelunch theoremï¼‰</a></li>
<li><a href="#%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8Fweight-decay">æƒé‡è¡°å‡ï¼ˆweight decayï¼‰</a></li>
<li><a href="#%E6%AD%A3%E5%88%99%E5%8C%96regularization">æ­£åˆ™åŒ–ï¼ˆregularizationï¼‰</a><ul>
<li><a href="#lasso-regularization">Lasso Regularization</a></li>
<li><a href="#ridge-regularization">Ridge Regularization</a></li>
<li><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88lasso-%E6%AF%94ridge-%E6%9B%B4%E7%A8%80%E7%96%8F-ridge%E6%AF%94lasso%E6%9B%B4%E5%B9%B3%E6%BB%91">ä¸ºä»€ä¹ˆLasso æ¯”Ridge æ›´ç¨€ç–ï¼Œ Ridgeæ¯”Lassoæ›´å¹³æ»‘</a></li>
</ul>
</li>
<li><a href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81">äº¤å‰éªŒè¯</a></li>
<li><a href="#%E9%A2%84%E6%B5%8B%E8%AF%AF%E5%B7%AEmeasures-prediction-errormse">é¢„æµ‹è¯¯å·®ï¼ˆmeasures prediction error,MSEï¼‰</a></li>
<li><a href="#underfitting-overfitting">Underfitting, Overfitting</a></li>
<li><a href="#%E6%84%9F%E7%9F%A5%E6%9C%BAperceptron">æ„ŸçŸ¥æœº(Perceptron)</a></li>
<li><a href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">ç›‘ç£å­¦ä¹ </a><ul>
<li><a href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92logistic-regression">é€»è¾‘å›å½’ï¼ˆlogistic regressionï¼‰</a></li>
<li><a href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BAsupport-vector-machine-svm">æ”¯æŒå‘é‡æœºï¼ˆsupport vector machine, SVM)</a></li>
<li><a href="#%E5%86%B3%E7%AD%96%E6%A0%91">å†³ç­–æ ‘</a></li>
<li><a href="#knn">KNN</a></li>
</ul>
</li>
<li><a href="#k-mean-%E7%AE%97%E6%B3%95">K Mean ç®—æ³•</a></li>
<li><a href="#em%E7%AE%97%E6%B3%95">EMç®—æ³•</a></li>
<li><a href="#bootstrap-%E9%87%87%E6%A0%B7%E6%B3%95">bootstrap é‡‡æ ·æ³•</a></li>
<li><a href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92">çº¿æ€§å›å½’</a></li>
<li><a href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97">éšæœºæ£®æ—</a></li>
<li><a href="#boosting-and-bagging">Boosting and bagging</a></li>
<li><a href="#xgboost">XGBoost</a></li>
<li><a href="#local-linear-embedding-lle">Local Linear Embedding (LLE)</a></li>
<li><a href="#sne-and-t-sne">SNE and t-SNE</a><ul>
<li><a href="#sne">SNE</a></li>
<li><a href="#t-sne">t-SNE</a></li>
</ul>
</li>
<li><a href="#cnn">CNN</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

<p>[TOC]</p>
<h2><span id="å‘é‡å’ŒçŸ©é˜µ">å‘é‡å’ŒçŸ©é˜µ</span></h2><p><strong>æ ‡é‡ï¼ˆscalar)</strong>: ä¸€ä¸ªæ ‡é‡è¡¨ç¤ºä¸€ä¸ªå•ç‹¬çš„æ•°</p>
<p><strong>å‘é‡(vector)</strong>: ä¸€ä¸ªå‘é‡è¡¨ç¤ºä¸€ç»„æœ‰åºæ’åˆ—çš„æ•°ã€‚</p>
<p><strong>çŸ©é˜µï¼ˆmatrix)</strong>: çŸ©é˜µæ˜¯å…·æœ‰ç›¸åŒç‰¹å¾å’Œçº¬åº¦çš„å¯¹è±¡çš„é›†åˆï¼Œè¡¨ç°ä¸ºä¸€å¼ äºŒç»´æ•°æ®è¡¨ã€‚</p>
<p><strong>å¼ é‡ï¼ˆtensor)</strong>: ä¸€ä¸ªæ•°ç»„ä¸­çš„å…ƒç´ åˆ†å¸ƒåœ¨è‹¥å¹²ç»´åæ ‡çš„è§„åˆ™ç½‘æ ¼ä¸­ï¼Œæˆ‘ä»¬å°†å…¶ç§°ä¹‹ä¸ºå¼ é‡ã€‚</p>
<p><strong>çŸ©é˜µä¹˜æ³•åçŸ©é˜µçš„å¤§å°</strong>: $$ a_{ik}*b_{kj}&#x3D;c_{ij}$$ </p>
<h2><span id="å‘é‡çš„èŒƒæ•°norm">å‘é‡çš„èŒƒæ•°(norm)</span></h2><p>å®šä¹‰ä¸€ä¸ªå‘é‡ä¸ºï¼š$\vec{a}&#x3D;[-5, 6, 8, -10]$ã€‚ä»»æ„ä¸€ç»„å‘é‡è®¾ä¸º$\vec{x}&#x3D;(x_1,x_2,â€¦,x_N)$ã€‚å…¶ä¸åŒèŒƒæ•°æ±‚è§£å¦‚ä¸‹ï¼š</p>
<ul>
<li>å‘é‡çš„1èŒƒæ•°ï¼šå‘é‡çš„å„ä¸ªå…ƒç´ çš„ç»å¯¹å€¼ä¹‹å’Œï¼Œä¸Šè¿°å‘é‡$\vec{a}$çš„1èŒƒæ•°ç»“æœå°±æ˜¯ï¼š29ã€‚</li>
</ul>
<p>$$<br>\Vert\vec{x}\Vert_1&#x3D;\sum_{i&#x3D;1}^N\vert{x_i}\vert<br>$$</p>
<ul>
<li>å‘é‡çš„2èŒƒæ•°ï¼šå‘é‡çš„æ¯ä¸ªå…ƒç´ çš„å¹³æ–¹å’Œå†å¼€å¹³æ–¹æ ¹ï¼Œä¸Šè¿°$\vec{a}$çš„2èŒƒæ•°ç»“æœå°±æ˜¯ï¼š15ã€‚</li>
</ul>
<p>$$<br>\Vert\vec{x}\Vert_2&#x3D;\sqrt{\sum_{i&#x3D;1}^N{\vert{x_i}\vert}^2}<br>$$</p>
<ul>
<li>å‘é‡çš„è´Ÿæ— ç©·èŒƒæ•°ï¼šå‘é‡çš„æ‰€æœ‰å…ƒç´ çš„ç»å¯¹å€¼ä¸­æœ€å°çš„ï¼šä¸Šè¿°å‘é‡$\vec{a}$çš„è´Ÿæ— ç©·èŒƒæ•°ç»“æœå°±æ˜¯ï¼š5ã€‚</li>
</ul>
<p>$$<br>\Vert\vec{x}\Vert_{-\infty}&#x3D;\min{|{x_i}|}<br>$$</p>
<ul>
<li>å‘é‡çš„æ­£æ— ç©·èŒƒæ•°ï¼šå‘é‡çš„æ‰€æœ‰å…ƒç´ çš„ç»å¯¹å€¼ä¸­æœ€å¤§çš„ï¼šä¸Šè¿°å‘é‡$\vec{a}$çš„æ­£æ— ç©·èŒƒæ•°ç»“æœå°±æ˜¯ï¼š10ã€‚</li>
</ul>
<p>$$<br>\Vert\vec{x}\Vert_{+\infty}&#x3D;\max{|{x_i}|}<br>$$</p>
<ul>
<li>å‘é‡çš„pèŒƒæ•°ï¼š</li>
</ul>
<p>$$<br>L_p&#x3D;\Vert\vec{x}\Vert_p&#x3D;\sqrt[p]{\sum_{i&#x3D;1}^{N}|{x_i}|^p}<br>$$</p>
<ul>
<li>ä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯ï¼ˆdot productï¼‰å¯ä»¥ç”¨èŒƒæ•°æ¥è¡¨ç¤º:</li>
</ul>
<p>$$<br>x^Ty&#x3D;\lVert x\rVert_2\lVert y\rVert_2cos\theta<br>$$</p>
<h2><span id="é€†çŸ©é˜µmatrix-inversion">é€†çŸ©é˜µ(matrix inversion)</span></h2><p>$$<br>A^{-1}A&#x3D;I<br>$$</p>
<p>or:<br>$$<br>AA^{-1}&#x3D;I<br>$$</p>
<h2><span id="å•ä½å‘é‡">å•ä½å‘é‡</span></h2><p>å•ä½å‘é‡ï¼ˆunit vectorï¼‰æ˜¯å…·æœ‰å•ä½èŒƒæ•°ï¼ˆunit normï¼‰çš„å‘é‡ï¼š<br>$$<br>\lVert x \rVert_2&#x3D;1<br>$$</p>
<h2><span id="æ­£äº¤çŸ©é˜µorthogonal-matrix">æ­£äº¤çŸ©é˜µï¼ˆorthogonal matrixï¼‰</span></h2><p>æ˜¯æŒ‡è¡Œå‘é‡å’Œåˆ—å‘é‡æ˜¯åˆ†åˆ«æ ‡å‡†æ­£äº¤çš„æ–¹é˜µï¼š<br>$$<br>A^TA&#x3D;AA^T&#x3D;1<br>$$<br>å³:<br>$$<br>A^{-1}&#x3D;A^T<br>$$</p>
<h2><span id="ç‰¹å¾åˆ†è§£eigendecomposition">ç‰¹å¾åˆ†è§£ï¼ˆeigendecomposition)</span></h2><p>æ–¹é˜µA çš„ç‰¹å¾å‘é‡ï¼ˆeigenvectorï¼‰æ˜¯æŒ‡ä¸A ç›¸ä¹˜åç›¸å½“äºå¯¹è¯¥å‘é‡è¿›è¡Œç¼©æ”¾<br>çš„éé›¶å‘é‡vï¼š<br>$$<br>Av&#x3D;\lambda v<br>$$</p>
<blockquote>
<p>vä¸ºå³ç‰¹å¾å‘é‡ï¼Œ$\lambda$ä¸ºç‰¹å¾å€¼</p>
</blockquote>
<p>æ‰€æœ‰ç‰¹å¾å€¼éƒ½æ˜¯æ­£æ•°çš„çŸ©é˜µè¢«ç§°ä¸ºæ­£å®šï¼ˆpositive definite)ï¼›æ‰€æœ‰ç‰¹å¾å€¼éƒ½æ˜¯éè´Ÿæ•°çš„çŸ©é˜µè¢«ç§°ä¸ºåŠæ­£å®šï¼ˆpositive semidefiniteï¼‰ã€‚åŒæ ·åœ°ï¼Œæ‰€æœ‰ç‰¹å¾å€¼éƒ½æ˜¯è´Ÿæ•°çš„çŸ©é˜µè¢«ç§°ä¸ºè´Ÿå®šï¼ˆnegative definite)ï¼›æ‰€æœ‰ç‰¹å¾å€¼éƒ½æ˜¯éæ­£æ•°çš„çŸ©é˜µè¢«ç§°ä¸ºåŠè´Ÿå®šï¼ˆnegative semidefiniteï¼‰</p>
<p>åŠæ­£å®šçŸ©é˜µ:<br>$$<br>\forall x, x^TAx \ge 0<br>$$<br>æ­£å®šçŸ©é˜µ:<br>$$<br>x^TAx&#x3D;0, \Rightarrow x&#x3D;0<br>$$</p>
<h2><span id="å¥‡å¼‚å€¼åˆ†è§£singular-value-decomposition-svd">å¥‡å¼‚å€¼åˆ†è§£ï¼ˆsingular value decomposition, SVD)</span></h2><p>å°†çŸ©é˜µA åˆ†è§£æˆä¸‰ä¸ªçŸ©é˜µçš„ä¹˜ç§¯:<br>$$<br>A&#x3D;UDV^T<br>$$</p>
<blockquote>
<p>A æ˜¯ä¸€ä¸ªmxn çš„çŸ©é˜µï¼Œé‚£ä¹ˆU æ˜¯ä¸€ä¸ªmxm çš„çŸ©é˜µï¼ŒD æ˜¯ä¸€ä¸ªmxn çš„çŸ©é˜µï¼ŒV æ˜¯ä¸€ä¸ªnxn çŸ©é˜µ</p>
<p>çŸ©é˜µU å’ŒV éƒ½å®šä¹‰ä¸ºæ­£äº¤çŸ©é˜µï¼Œè€ŒçŸ©é˜µD å®šä¹‰ä¸ºå¯¹è§’çŸ©é˜µã€‚æ³¨æ„ï¼ŒçŸ©é˜µD ä¸ä¸€å®šæ˜¯æ–¹é˜µã€‚</p>
<p>A çš„å·¦å¥‡å¼‚å‘é‡ï¼ˆleft singular vectorï¼‰æ˜¯$AA^âŠ¤$ çš„ç‰¹å¾å‘é‡ã€‚A çš„å³å¥‡å¼‚å‘é‡ï¼ˆright singularvectorï¼‰æ˜¯$A^âŠ¤A$ çš„ç‰¹å¾å‘é‡ã€‚A çš„éé›¶å¥‡å¼‚å€¼æ˜¯$A^âŠ¤A$ ç‰¹å¾å€¼çš„å¹³æ–¹æ ¹ï¼ŒåŒæ—¶ä¹Ÿæ˜¯A$A^âŠ¤$ ç‰¹å¾å€¼çš„å¹³æ–¹æ ¹ã€‚</p>
</blockquote>
<h2><span id="è¿¹è¿ç®—">è¿¹è¿ç®—</span></h2><p>è¿¹è¿ç®—è¿”å›çš„æ˜¯çŸ©é˜µå¯¹è§’å…ƒç´ çš„å’Œï¼š<br>$$<br>Tr(A) &#x3D; \sum_iA_{i,i}<br>$$</p>
<p>$$<br>Tr(ABC)&#x3D;Tr(CAB)&#x3D;Tr(BCA)<br>$$</p>
<h2><span id="ä¸»æˆåˆ†åˆ†æprincipal-components-analysis-pca">ä¸»æˆåˆ†åˆ†æï¼ˆprincipal components analysis, PCAï¼‰</span></h2><p><strong>PCAä¸»è¦è¦æ±‚:</strong></p>
<ol>
<li><strong>æœ€å¤§æ–¹å·®</strong></li>
<li><strong>æœ€å°é”™è¯¯</strong></li>
</ol>
<blockquote>
<p>åœ¨ä¿¡å·å¤„ç†ä¸­è®¤ä¸ºä¿¡å·å…·æœ‰è¾ƒå¤§çš„æ–¹å·®ï¼Œå™ªå£°æœ‰è¾ƒå°çš„æ–¹å·®ï¼Œä¿¡å™ªæ¯”å°±æ˜¯ä¿¡å·ä¸å™ªå£°çš„æ–¹å·®æ¯”ï¼Œè¶Šå¤§è¶Šå¥½ã€‚</p>
</blockquote>
<p><strong>æœ€å°é”™è¯¯</strong>:</p>
<p><img src="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/pca_mim_distance.JPG" alt="avatar"></p>
<p><strong>æœ€å¤§æ–¹å·®</strong>:</p>
<p><img src="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/pca_var.JPG" alt="avatar"></p>
<blockquote>
<p>Var(X)&#x3D;E($X^2$)-$E(X)^2$ -&gt; centered: E(X)&#x3D;0</p>
</blockquote>
<p><strong>ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•</strong>:<br>$$<br>L(w,\lambda)&#x3D;w^TSw+\lambda(1-w^Tw)\<br>\frac{\delta L}{\delta w} &#x3D; 2Sw-2\lambda w\<br>Sw&#x3D;\lambda w\<br>(S-\lambda I)w&#x3D;0<br>$$<br><img src="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/pca_1.JPG" alt="avatar"></p>
<p><img src="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/pca_2.JPG" alt="avatar"></p>
<p><strong>Result</strong>:</p>
<p><img src="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/image-20210416140003841.png"></p>
<p><strong>4. PCAç†è®ºæ„ä¹‰</strong>:</p>
<p>PCAå°†nä¸ªç‰¹å¾é™ç»´åˆ°kä¸ªï¼Œå¯ä»¥ç”¨æ¥è¿›è¡Œæ•°æ®å‹ç¼©ï¼Œå¦‚æœ100ç»´çš„å‘é‡æœ€åå¯ä»¥ç”¨10ç»´æ¥è¡¨ç¤ºï¼Œé‚£ä¹ˆå‹ç¼©ç‡ä¸º90%ã€‚åŒæ ·å›¾åƒå¤„ç†é¢†åŸŸçš„KLå˜æ¢ä½¿ç”¨PCAåšå›¾åƒå‹ç¼©ã€‚ä½†PCAè¦ä¿è¯é™ç»´åï¼Œè¿˜è¦ä¿è¯æ•°æ®çš„ç‰¹æ€§æŸå¤±æœ€å°ã€‚</p>
<blockquote>
<p>PCAå¯¹äºoutlierså¹¶ä¸æ˜¯robust</p>
</blockquote>
<p>å¯ä»¥é…åˆWhiteningï¼Œ</p>
<p><img src="https://images0.cnblogs.com/blog/670089/201501/081543500006068.png" alt="img"></p>
<p>ä½¿å„è‡ªçš„varianceéƒ½ä¸º1</p>
<h2><span id="æ¦‚ç‡è®º">æ¦‚ç‡è®º</span></h2><h3><span id="ä¿¡ä»»åº¦degree-of-belief">ä¿¡ä»»åº¦(degree of belief):</span></h3><p>åœ¨åŒ»ç”Ÿè¯Šæ–­ç—…äººçš„ä¾‹å­ä¸­ï¼Œå…¶ä¸­1 è¡¨ç¤ºéå¸¸è‚¯å®šç—…äººæ‚£æœ‰æµæ„Ÿï¼Œè€Œ0 è¡¨ç¤ºéå¸¸è‚¯å®šç—…äººæ²¡æœ‰æµæ„Ÿã€‚</p>
<h3><span id="å½’ä¸€åŒ–normalized">å½’ä¸€åŒ–ï¼ˆnormalizedï¼‰</span></h3><p>$$<br>\sum P(x)&#x3D;1<br>$$</p>
<h3><span id="ç¦»æ•£å‡åŒ€åˆ†å¸ƒuniform-distribution">ç¦»æ•£å‡åŒ€åˆ†å¸ƒï¼ˆuniform distributionï¼‰:</span></h3><p>è€ƒè™‘ä¸€ä¸ªç¦»æ•£å‹éšæœºå˜é‡x æœ‰k ä¸ªä¸åŒçš„çŠ¶æ€:<br>$$<br>P(x&#x3D;x_i)&#x3D;\frac{1}{k}<br>$$</p>
<h3><span id="æ¦‚ç‡å¯†åº¦å‡½æ•°probability-density-function">æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆprobability density function):</span></h3><p>ç ”ç©¶çš„å¯¹è±¡æ˜¯è¿ç»­å‹éšæœºå˜é‡, ä¸”æ»¡è¶³ä»¥ä¸‹æ¡ä»¶:</p>
<ul>
<li>p çš„å®šä¹‰åŸŸå¿…é¡»æ˜¯x æ‰€æœ‰å¯èƒ½çŠ¶æ€çš„é›†åˆã€‚</li>
<li>$\forall x,p(x)\ge0$</li>
<li>$\int p(x)dx&#x3D;1$</li>
</ul>
<h4><span id="è¿ç»­å‡åŒ€åˆ†å¸ƒ">è¿ç»­å‡åŒ€åˆ†å¸ƒ:</span></h4><p>x åœ¨[a; b] ä¸Šæ˜¯å‡åŒ€åˆ†å¸ƒçš„:<br>$$<br>u(x;a,b) &#x3D; \frac{1}{b-a}<br>$$</p>
<h3><span id="é“¾å¼æ³•åˆ™chain-rule">é“¾å¼æ³•åˆ™ï¼ˆchain ruleï¼‰:</span></h3><p>$$<br>P(a, b, c) &#x3D; P(a | b, c)P(b | c)P(c)<br>$$</p>
<h3><span id="ç‹¬ç«‹æ€§independent">ç‹¬ç«‹æ€§ï¼ˆindependentï¼‰:</span></h3><p>$$<br>\forall x,y\ \ \ p(x,y)&#x3D;p(x)p(y)<br>$$</p>
<h3><span id="æœŸæœ›expectation">æœŸæœ›ï¼ˆexpectationï¼‰:</span></h3><p><strong>ç¦»æ•£æœŸæœ›</strong>:<br>$$<br>\sum P(x)f(x)<br>$$<br><strong>è¿ç»­æœŸæœ›:</strong><br>$$<br>\int p(x)f(X)dx<br>$$</p>
<h3><span id="æ–¹å·®variance">æ–¹å·®ï¼ˆvarianceï¼‰:</span></h3><p>$$<br>Var(x)&#x3D;E[x^2-2xE[x]+E[x]^2]&#x3D;E[x^2]-2E[x]E[x]-E[x]^2&#x3D;E[x^2]-E[x]^2<br>$$</p>
<h3><span id="åæ–¹å·®covariance">åæ–¹å·®ï¼ˆcovarianceï¼‰:</span></h3><p>$$<br>Var(x)&#x3D;cov(x,x)&#x3D;E[(X-E[X])(Y-E[Y])]&#x3D;E[XY]-E[X]E[Y]<br>$$</p>
<p>åæ–¹å·®çš„ç»å¯¹å€¼å¦‚æœå¾ˆå¤§åˆ™æ„å‘³ç€å˜é‡å€¼å˜åŒ–å¾ˆå¤§å¹¶ä¸”å®ƒä»¬åŒæ—¶è·ç¦»å„è‡ªçš„å‡å€¼å¾ˆè¿œã€‚å¦‚æœåæ–¹å·®æ˜¯æ­£çš„ï¼Œé‚£ä¹ˆä¸¤ä¸ªå˜é‡éƒ½å€¾å‘äºåŒæ—¶å–å¾—ç›¸å¯¹è¾ƒå¤§çš„å€¼ã€‚å¦‚æœåæ–¹å·®æ˜¯è´Ÿçš„ï¼Œé‚£ä¹ˆå…¶ä¸­ä¸€ä¸ªå˜é‡å€¾å‘äºå–å¾—ç›¸å¯¹è¾ƒå¤§çš„å€¼çš„åŒæ—¶ï¼Œå¦ä¸€ä¸ªå˜é‡å€¾å‘äºå–å¾—ç›¸å¯¹è¾ƒå°çš„å€¼ï¼Œåä¹‹äº¦ç„¶ã€‚å…¶ä»–çš„è¡¡é‡æŒ‡æ ‡å¦‚ç›¸å…³ç³»æ•°ï¼ˆcorrelationï¼‰å°†æ¯ä¸ªå˜é‡çš„è´¡çŒ®å½’ä¸€åŒ–ï¼Œä¸ºäº†åªè¡¡é‡å˜é‡çš„ç›¸å…³æ€§è€Œä¸å—å„ä¸ªå˜é‡å°ºåº¦å¤§å°çš„å½±å“ã€‚</p>
<h3><span id="å¸¸ç”¨æ¦‚ç‡åˆ†å¸ƒ">å¸¸ç”¨æ¦‚ç‡åˆ†å¸ƒ</span></h3><p><strong>Bernoulli åˆ†å¸ƒ:</strong></p>
<p>Bernoulli åˆ†å¸ƒï¼ˆBernoulli distributionï¼‰æ˜¯å•ä¸ªäºŒå€¼éšæœºå˜é‡çš„åˆ†å¸ƒ:<br>$$<br>P(x&#x3D;1)&#x3D;\phi\<br>P(x&#x3D;0)&#x3D;1-\phi\<br>P(X&#x3D;x)&#x3D;\phi^x(1-\phi)^{1-x}<br>$$</p>
<p><strong>é«˜æ–¯åˆ†å¸ƒ(Gaussian distribution)</strong></p>
<p>å®æ•°ä¸Šæœ€å¸¸ç”¨çš„åˆ†å¸ƒå°±æ˜¯æ­£æ€åˆ†å¸ƒï¼ˆnormal distributionï¼‰ï¼Œä¹Ÿç§°ä¸ºé«˜æ–¯åˆ†å¸ƒï¼ˆGaussian distributionï¼‰ï¼š<br>$$<br>N(x;\mu,\sigma^2)&#x3D;\sqrt{\frac{1}{2\pi\sigma^2}}exp(-\frac{1}{2\sigma^2}(x-\mu)^2)<br>$$</p>
<p><strong>å¤šç»´æ­£æ€åˆ†å¸ƒï¼ˆmultivariatenormal distributionï¼‰:</strong><br>$$<br>N(x;\mu,\Sigma)&#x3D;\sqrt{\frac{1}{(2\pi)^ndet(\Sigma)}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))<br>$$</p>
<p><strong>Beta åˆ†å¸ƒ:</strong></p>
<p>$\alpha &#x3D; 1, \beta &#x3D;1$ -&gt; æ²¡æœ‰ç»éªŒ</p>
<p>$\alpha&#x3D;5,\beta&#x3D;5$ -&gt; é»˜è®¤æ˜¯å‡åŒ€åˆ†å¸ƒ</p>
<p>Betaåˆ†å¸ƒé€šå¸¸ç”¨äºäºŒé¡¹åˆ†å¸ƒçš„å…ˆéªŒæ¦‚ç‡</p>
<p><strong>Dirac åˆ†å¸ƒï¼ˆDirac delta functionï¼‰:</strong><br>$$<br>p(x)&#x3D;\delta(x-u)<br>$$<br>åœ¨uå¤„æ— ç©·å¤§ï¼Œå…¶ä»–å¤„ä¸º0</p>
<p>Dirac åˆ†å¸ƒç»å¸¸ä½œä¸ºç»éªŒåˆ†å¸ƒï¼ˆempirical distributionï¼‰çš„ä¸€ä¸ªç»„æˆéƒ¨åˆ†å‡ºç°ï¼š<br>$$<br>p(x)&#x3D;\frac{1}{m}\sum \delta(x-x^{i})<br>$$<br>ç»éªŒåˆ†å¸ƒå°†æ¦‚ç‡å¯†åº¦$\frac{1}{m}$ èµ‹ç»™m ä¸ªç‚¹$x^{(1)},â€¦,x^{(m)}$ ä¸­çš„æ¯ä¸€ä¸ªï¼Œè¿™äº›ç‚¹æ˜¯ç»™å®šçš„<br>æ•°æ®é›†æˆ–è€…é‡‡æ ·çš„é›†åˆã€‚é€šå¸¸å¤šé¡¹åˆ†å¸ƒçš„å…ˆéªŒæ¦‚ç‡</p>
<p><strong>logistic sigmoid å‡½æ•°â€™:</strong><br>$$<br>\sigma(x)&#x3D;\frac{1}{1+exp(-x)}\<br>\Rightarrow\sigma(x)&#x3D;\frac{exp(x)}{exp(x)+exp(0)}\<br>$$</p>
<p><img src="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/sigmoid.JPG"></p>
<p>å¤šç”¨äºå¤šæ ‡ç­¾åˆ†ç±»ï¼Œå°†ä»»æ„çš„å€¼è½¬æ¢ä¸º[0,1]ä¹‹é—´ï¼Œå¤šç”¨äºè¾“å‡ºå±‚ï¼Œå¯èƒ½æœ‰å¤šä¸ªæ­£ç¡®ç­”æ¡ˆï¼Œå¯ä»¥é€‰æ‹©å¤šä¸ªç­”æ¡ˆ<br>$$<br>sigmoidå¯¼æ•°ï¼šsigmoid*(1-sigmoid)<br>$$<br>ç¼ºç‚¹ï¼š</p>
<ul>
<li>ä¸¤ç«¯æ¢¯åº¦æ¶ˆå¤±</li>
<li>ä¸ºæŒ‡æ•°å½¢å¼ï¼Œè®¡ç®—é‡å¤§</li>
</ul>
<p><strong>softmaxå‡½æ•°</strong></p>
<p><strong>Softmaxå‡½æ•°</strong>ï¼Œåˆç§°å½’ä¸€åŒ–æŒ‡æ•°å‡½æ•°ï¼Œè¾“å‡ºä¸ºäº’æ–¥è¾“å‡º<br>$$<br>softmax(x) &#x3D; \frac{e^{x_i}}{\sum{e^{x_i}}}<br>$$<br>è¾“å‡ºå€¼çš„å’Œä¸º1ï¼Œä½œä¸ºæˆ‘ä»¬çš„é¢„æµ‹ç›®æ ‡ï¼Œsoftmaxä½œä¸ºMLP(å¤šå±‚æ„ŸçŸ¥æœº)çš„æœ€åä¸€å±‚ï¼Œå¹¶é…åˆä»¥äº¤å‰ç†µæŸå¤±å‡½æ•°</p>
<p><strong>è´å¶æ–¯è§„åˆ™ï¼ˆBayesâ€™ ruleï¼‰</strong><br>$$<br>P(x|y)&#x3D;\frac{P(x)P(y|x)}{P(y)}<br>$$</p>
<p><strong>è‡ªä¿¡æ¯ï¼ˆself-informationï¼‰:</strong><br>$$<br>I(x)&#x3D;-logP(x)<br>$$<br>ä¸å¯èƒ½å‘ç”Ÿçš„äº‹ä»¶å…·æœ‰æ›´é«˜çš„ä¿¡æ¯é‡</p>
<p><strong>é¦™å†œç†µï¼ˆShannon entropyï¼‰:</strong></p>
<p>ç†µæ˜¯ä¸ç¡®å®šæ€§çš„ä¸€ç§åº¦é‡ã€‚å¯ä»¥è¡¨ç¤ºä¸€ä¸ªäº‹ä»¶çš„è‡ªä¿¡æ¯é‡ï¼Œä¹Ÿå°±æ˜¯AåŒ…å«å¤šå°‘ä¿¡æ¯ã€‚<br>$$<br>H(x)&#x3D;E[I(x)]&#x3D;-E[logP(x)]&#x3D;-pIn(p)-(1-p)In(1-p)<br>$$</p>
<p><strong>KL æ•£åº¦ï¼ˆKullback-Leibler (KL) divergenceï¼‰:</strong><br>$$<br>D_{KL}(P||Q)&#x3D;E[log\frac{P(x)}{Q(x)}]&#x3D;E[logP(x)-logQ(x)]<br>$$<br>å¦‚æœæˆ‘ä»¬å¯¹äºåŒä¸€ä¸ªéšæœºå˜é‡x æœ‰ä¸¤ä¸ªå•ç‹¬çš„æ¦‚ç‡åˆ†å¸ƒP(x) å’ŒQ(x)ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨KL æ•£åº¦ï¼ˆKullback-Leibler (KL) divergenceï¼‰æ¥<strong>è¡¡é‡è¿™ä¸¤ä¸ªåˆ†å¸ƒçš„å·®å¼‚</strong>,KL æ•£åº¦æœ‰å¾ˆå¤šæœ‰ç”¨çš„æ€§è´¨ï¼Œæœ€é‡è¦çš„æ˜¯å®ƒæ˜¯<strong>éè´Ÿçš„</strong>ã€‚<strong>KL æ•£åº¦ä¸º0 å½“ä¸”ä»…å½“P å’ŒQ åœ¨ç¦»æ•£å‹å˜é‡çš„æƒ…å†µä¸‹æ˜¯ç›¸åŒçš„åˆ†å¸ƒ</strong>ï¼Œæˆ–è€…åœ¨è¿ç»­å‹å˜é‡çš„æƒ…å†µä¸‹æ˜¯â€˜â€˜å‡ ä¹å¤„å¤„â€™â€™ ç›¸åŒçš„ã€‚å› ä¸ºKL æ•£åº¦æ˜¯éè´Ÿçš„å¹¶ä¸”è¡¡é‡çš„æ˜¯ä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ï¼Œå®ƒç»å¸¸è¢«ç”¨ä½œåˆ†å¸ƒä¹‹é—´çš„æŸç§è·ç¦»ã€‚ç„¶è€Œï¼Œå®ƒå¹¶ä¸æ˜¯çœŸçš„è·ç¦»å› ä¸ºå®ƒä¸æ˜¯å¯¹ç§°çš„ï¼šå¯¹äºæŸäº›P å’ŒQï¼Œ$D_{KL}(P||Q)\ne D_{KL}(Q||P)$ ,</p>
<p><strong>äº¤å‰ç†µï¼ˆcross-entropyï¼‰:</strong><br>$$<br>H(P,Q) &#x3D; H(P) +D_{KL}(P||Q)<br>$$</p>
<p>$$<br>\Rightarrow\ \ H(P,Q)&#x3D;-E[logQ(x)]<br>$$</p>
<p><strong>å¦‚æœç†µæ˜¯ä¸€ä¸ªå¸¸é‡ï¼Œé‚£ä¹ˆKLæ•£åº¦å’Œäº¤å‰ç†µåœ¨ç‰¹å®šæ¡ä»¶ä¸‹ç­‰ä»·ã€‚</strong>äº¤å‰ç†µè¶Šä½ï¼Œå°±è¯æ˜ç”±ç®—æ³•æ‰€äº§ç”Ÿçš„ç­–ç•¥æœ€æ¥è¿‘æœ€ä¼˜ç­–ç•¥ï¼Œä¹Ÿé—´æ¥è¯æ˜æˆ‘ä»¬ç®—æ³•æ‰€ç®—å‡ºçš„éçœŸå®åˆ†å¸ƒè¶Šæ¥è¿‘çœŸå®åˆ†å¸ƒã€‚</p>
<p>çœŸå®åˆ†å¸ƒ <img src="https://www.zhihu.com/equation?tex=p_k+=+(%5Cfrac+%7B1%7D%7B2%7D,%5Cfrac+%7B1%7D%7B4%7D,%5Cfrac+%7B1%7D%7B8%7D,%5Cfrac+%7B1%7D%7B8%7D)" alt="[å…¬å¼]"> ï¼Œ éçœŸå®åˆ†å¸ƒ <img src="https://www.zhihu.com/equation?tex=q_k+=+(%5Cfrac+%7B1%7D%7B4%7D,%5Cfrac+%7B1%7D%7B4%7D,%5Cfrac+%7B1%7D%7B4%7D,%5Cfrac+%7B1%7D%7B4%7D)" alt="[å…¬å¼]"> ï¼Œäº¤å‰ç†µä¸º <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7B2%7D+*+%5Clog_2+4+++%5Cfrac%7B1%7D%7B4%7D+*+%5Clog_2+4+++%5Cfrac%7B1%7D%7B8%7D+*+%5Clog_2+4+++%5Cfrac%7B1%7D%7B8%7D+*+%5Clog_2+4+=+2" alt="[å…¬å¼]"> </p>
<p><strong>æ‰€ä»¥é€»è¾‘æ€è·¯æ˜¯ï¼Œä¸ºäº†è®©å­¦åˆ°çš„æ¨¡å‹åˆ†å¸ƒæ›´è´´è¿‘çœŸå®æ•°æ®åˆ†å¸ƒï¼Œæˆ‘ä»¬æœ€å°åŒ– æ¨¡å‹æ•°æ®åˆ†å¸ƒ ä¸ è®­ç»ƒæ•°æ®ä¹‹é—´çš„KLæ•£åº¦ï¼Œè€Œå› ä¸ºè®­ç»ƒæ•°æ®çš„åˆ†å¸ƒæ˜¯å›ºå®šçš„ï¼Œå› æ­¤æœ€å°åŒ–KLæ•£åº¦ç­‰ä»·äºæœ€å°åŒ–äº¤å‰ç†µã€‚</strong></p>
<p><strong>å› ä¸ºç­‰ä»·ï¼Œè€Œä¸”äº¤å‰ç†µæ›´ç®€å•æ›´å¥½è®¡ç®—ï¼Œå½“ç„¶ç”¨å®ƒ</strong></p>
<p><strong>FP, FN, TP, TN</strong></p>
<p>TP: True Positive, çœŸçš„é¢„æµ‹ä¹Ÿä¸ºçœŸ</p>
<p>TN: True Negative,å‡çš„é¢„æµ‹ä¹Ÿä¸ºå‡</p>
<p>FP: False Positive,å‡çš„é¢„æµ‹ä¸ºçœŸ</p>
<p>FN: False Nagative,çœŸçš„é¢„æµ‹ä¸ºå‡</p>
<p><strong>Precision, Recall and Accurancy</strong></p>
<p>Precision: is the accuracy of the positive predictions<br>$$<br>\frac{TP}{TP+FP}<br>$$<br>Recall: is the accuracy of the positive class<br>$$<br>\frac{TP}{TP+FN}<br>$$<br>Accurancy:<br>$$<br>\frac{TP+NP}{TP+NP+TN+FN}<br>$$<br><strong>True positive rate, False positive rate</strong><br>$$<br>True\ positive\ rate &#x3D; \frac{TP}{TP+FN}<br>$$</p>
<p>$$<br>False\ positive\ rate&#x3D;\frac{FP}{TN+FP}<br>$$</p>
<p><strong>$F_1$ Score</strong></p>
<p>ä¸ºäº†å¹³è¡¡Precisionå’ŒRecall,æ¥ç»™å‡ºæ¨¡å‹çš„è¯„ä¼°å€¼ï¼Œ $F_1$ Score å°±è¢«ä½¿ç”¨äº†ï¼Œ$F_1$ Scoreå…¶å®å°±æ˜¯Precisionå’ŒRecallçš„è°ƒå’Œå¹³å‡æ•°(Harmonic mean)<br>$$<br>2\frac{1}{\frac{1}{Precision}+\frac{1}{Recall}} &#x3D; \frac{2<em>Precision</em>Recall}{Precision+Recall}<br>$$<br><strong>$F_\beta$ Score</strong><br>$$<br>(1+\beta^2)\frac{Precision*Recall}{\beta^2Precision+Recall}<br>$$<br> <strong>PR Curve</strong></p>
<p><img src="https://habrastorage.org/files/010/ded/77e/010ded77e8d0454b99f0cafd3d962613.png"></p>
<p>é˜ˆå€¼ä»å¤§åˆ°å°ï¼Œå¦‚æœä¸€å¼€å§‹Precisionä¸º1ï¼Œåˆ™è¯´æ˜é«˜é˜ˆå€¼ä¸‹çš„åˆ†ç±»éƒ½ä¸ºæ­£ç¡®ï¼Œæœ€årecallä¸º1ï¼Œè¯´æ˜æ­£ç¡®åˆ†ç±»äº†ï¼Œä½†æ˜¯é”™è¯¯è¢«åˆ†ä¸ºæ­£ç¡®çš„åˆ—å­ä¹Ÿå¢åŠ äº†ã€‚</p>
<p>åœ¨ä¸€å®šç¨‹åº¦ä¸Šï¼ŒPR æ˜¯çŸ›ç›¾çš„ï¼Œæ‰€ä»¥å¯ä»¥ç”¨$F_1 Score$æ¥è¯„å®š</p>
<p><strong>Receiver Operating Characteristic (ROC) Curve</strong></p>
<p>ROC &#x3D; TPR VS FPR</p>
<p>AUCè¶Šå¤§ï¼Œè¯´æ˜åˆ†ç±»å™¨è¶Šå¯èƒ½æŠŠçœŸæ­£çš„æ­£æ ·æœ¬æ’åœ¨å‰é¢ï¼Œåˆ†ç±»æ€§èƒ½è¶Šå¥½ã€‚</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/6/6b/Roccurves.png"></p>
<p>**AUC ROC **</p>
<p>AUC ROC &#x3D; area under the ROC curve</p>
<p>å½“æ­£è´Ÿæ ·æœ¬çš„åˆ†å¸ƒå‘ç”Ÿå˜åŒ–æ—¶ï¼ŒROCæ›²çº¿çš„å½¢çŠ¶èƒ½å¤ŸåŸºæœ¬ä¿æŒä¸å˜ï¼Œè€ŒP-Ræ›²çº¿çš„å½¢çŠ¶ä¸€èˆ¬ä¼šå‘ç”Ÿè¾ƒå‰§çƒˆçš„å˜åŒ–ã€‚</p>
<h2><span id="æ•°å€¼è®¡ç®—">æ•°å€¼è®¡ç®—</span></h2><h3><span id="jacobiançŸ©é˜µ">JacobiançŸ©é˜µ</span></h3><p>$$<br>J_{i,j} &#x3D; \frac{\delta}{\delta x_j}f(x)_i<br>$$</p>
<h2><span id="hessian-çŸ©é˜µ">Hessian çŸ©é˜µ</span></h2><p>$$<br>H(f)(x)_{i,j} &#x3D; \frac{\delta ^2}{\delta x_i \delta x_j}f(x)<br>$$</p>
<p>Hessian çŸ©é˜µå¯ä»¥çœ‹ä¸º JacobiançŸ©é˜µçš„æ¢¯åº¦ã€‚</p>
<p>å½“Hessian æ˜¯æ­£å®šçš„ï¼ˆæ‰€æœ‰ç‰¹å¾å€¼éƒ½æ˜¯æ­£çš„ï¼‰ï¼Œåˆ™è¯¥ä¸´ç•Œç‚¹æ˜¯å±€éƒ¨æå°ç‚¹ã€‚å› ä¸ºæ–¹å‘äºŒé˜¶å¯¼æ•°åœ¨ä»»æ„æ–¹å‘éƒ½æ˜¯æ­£çš„ï¼Œå‚è€ƒå•å˜é‡çš„äºŒé˜¶å¯¼æ•°æµ‹è¯•å°±èƒ½å¾—å‡ºæ­¤ç»“è®ºã€‚åŒæ ·çš„ï¼Œå½“Hessian æ˜¯è´Ÿå®šçš„ï¼ˆæ‰€æœ‰ç‰¹å¾å€¼éƒ½æ˜¯è´Ÿçš„ï¼‰ï¼Œè¿™ä¸ªç‚¹å°±æ˜¯å±€éƒ¨æå¤§ç‚¹ã€‚</p>
<p>é»‘å¡çŸ©é˜µæ˜¯æ˜¯å¯¹ç§°çŸ©é˜µï¼Œå¯åˆ†è§£ä¸º<br>$$<br>H&#x3D;E\Lambda E^T<br>$$<br>$\Lambda$ æ˜¯ç‰¹å¾å‘é‡ï¼ŒEæ˜¯å•ä½å‘é‡<br>$$<br>Av&#x3D;\lambda v<br>$$<br>$v$ä¸ºç‰¹å¾å‘é‡ï¼Œ$\lambda$ ä¸ºç‰¹å¾å€¼ï¼Œå¦‚æœç‰¹è¯Šå€¼ä¸ºæ­£ï¼Œåˆ™è¡¨æ˜ç»è¿‡çº¿æ€§å˜åŒ–åï¼Œæ–¹å‘ä¸å˜ï¼Œä¸ºè´Ÿï¼Œåˆ™æ–¹å‘ç›¸åï¼Œä¸º0åˆ™ç¼©å›åŸç‚¹ã€‚$\lambda$ çš„æ•°å€¼å¤§å°è¡¨ç¤ºç¼©æ”¾å¤§å°ã€‚å®å¯¹ç§°çŸ©é˜µï¼Œä¸åŒç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡å¿…å®šæ­£äº¤ã€‚</p>
<h3><span id="karushkuhntuckerkkt">Karushâ€“Kuhnâ€“Tuckerï¼ˆKKTï¼‰</span></h3><p>åŠ å…¥ g(i) ç§°ä¸ºç­‰å¼çº¦æŸï¼ˆequality constraintï¼‰ã€‚æ¶‰åŠh(j) çš„ä¸ç­‰å¼ç§°ä¸ºä¸ç­‰å¼çº¦æŸï¼ˆinequality constraintï¼‰ã€‚æˆ‘ä»¬ä¸ºæ¯ä¸ªçº¦æŸå¼•å…¥æ–°çš„å˜é‡$\lambda_i$ å’Œ$\alpha_j$ï¼Œè¿™äº›æ–°å˜é‡è¢«ç§°ä¸ºKKT ä¹˜å­ã€‚<br>$$<br>L(x,\lambda,\alpha) &#x3D; f(x) + \sum \lambda g(x)+\sum \alpha h(x)<br>$$<br>æ»¡è¶³æ¡ä»¶:</p>
<ul>
<li>$\frac{\delta L}{\delta x}&#x3D;0$</li>
<li>$\lambda \ge 0$</li>
<li>$\lambda h(x)&#x3D;0$</li>
</ul>
<h2><span id="è·ç¦»é€‰æ‹©å…¬å¼">è·ç¦»é€‰æ‹©å…¬å¼</span></h2><h3><span id="æ¬§å‡ é‡Œå¾—è·ç¦»">æ¬§å‡ é‡Œå¾—è·ç¦»</span></h3><p>$$<br>d &#x3D; \sqrt{(x_1-x_2)^2+(y_1-y_2)^2}<br>$$</p>
<h3><span id="æ›¼å“ˆé¡¿è·ç¦»">æ›¼å“ˆé¡¿è·ç¦»</span></h3><p>$$<br>d &#x3D; |x_1-x_2|+|y_1-y_2|<br>$$</p>
<h2><span id="è´å¶æ–¯å®šç†">è´å¶æ–¯å®šç†</span></h2><p>$$<br>P(\theta | D) &#x3D; \frac{P(\theta)P(D|\theta)}{P(D)}<br>$$</p>
<blockquote>
<p>$\theta$ è¡¨ç¤ºæ¨¡å‹å‚æ•°ï¼ŒDè¡¨ç¤ºæ•°æ®</p>
<p>P($\theta$) æ˜¯å…ˆéªŒæ¦‚ç‡ï¼ŒP(D|$\theta$) ä¸ºä¼¼ç„¶å‡½æ•°ï¼ŒP($\theta$|D)æ˜¯åéªŒæ¦‚ç‡ </p>
</blockquote>
<h2><span id="æœ´ç´ è´å¶æ–¯naive-bayesian-algorithm">æœ´ç´ è´å¶æ–¯(Naive Bayesian algorithm)</span></h2><p><img src="https://pic2.zhimg.com/80/v2-a2a73f43adcbb0bf4b9bae19b9495f81_1440w.png" alt="avatar"></p>
<p><strong>p(ä¸å¸…ã€æ€§æ ¼ä¸å¥½ã€èº«é«˜çŸ®ã€ä¸ä¸Šè¿›|å«) &#x3D; p(ä¸å¸…|å«)*p(æ€§æ ¼ä¸å¥½|å«)*p(èº«é«˜çŸ®|å«)*p(ä¸ä¸Šè¿›|å«)</strong></p>
<h3><span id="æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘å¤„ç†laplace-smoothing">æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘å¤„ç†(Laplace Smoothing)</span></h3><p>ä¸»è¦ç”¨äºè§£å†³æŸäº›ç‰¹å¾æœªå‡ºç°åœ¨æ•°æ®é›†ä¸­ï¼Œä»è€Œå¯¼è‡´P(ç‰¹å¾|ç±»åˆ«)ä¸º0è€Œå¯¼è‡´è®¡ç®—å‡ºç°é—®é¢˜ã€‚</p>
<p>æ€§æ ¼ç‰¹å¾çš„ä¸ªæ•°ä¸ºçˆ†å¥½ï¼Œå¥½ï¼Œä¸å¥½ï¼Œä¸‰ç§æƒ…å†µï¼Œé‚£ä¹ˆ<img src="https://www.zhihu.com/equation?tex=S_%7Bj%7D+" alt="[å…¬å¼]">ä¸º3ï¼Œåˆ™æœ€ç»ˆæ¦‚ç‡ä¸º1&#x2F;9 ï¼ˆ<strong>å«çš„ä¸ªæ•°ä¸º6+ç‰¹å¾ä¸ªæ•°ä¸º3</strong>)<br>$$<br>\frac{1}{æ­¤ç‰¹å¾æ•°é‡+æ­¤æ ‡ç­¾çš„æ•°é‡}<br>$$</p>
<h2><span id="æŸå¤±å‡½æ•°loss-functionæˆ–ä»£ä»·å‡½æ•°cost-function">æŸå¤±å‡½æ•°(loss function)æˆ–ä»£ä»·å‡½æ•°(cost function)</span></h2><p>ç”¨äºåº¦é‡é¢„æµ‹é”™è¯¯çš„ç¨‹åº¦ã€‚</p>
<h3><span id="å¹³æ–¹æŸå¤±å‡½æ•°quadratic-loss-function">å¹³æ–¹æŸå¤±å‡½æ•°(quadratic loss function)</span></h3><p>$$<br>L(Y,f(x)) &#x3D; (Y-f(x))^2<br>$$</p>
<h3><span id="ç»éªŒæŸå¤±empirical-loss-r_emp">ç»éªŒæŸå¤±(empirical loss) $R_{emp}$</span></h3><p>$$<br>R_{emp}(f)&#x3D;\frac{1}{N}\sum_i L(y_i,f(x_i))<br>$$</p>
<p>å½“æ ·æœ¬å®¹é‡å¾ˆå°æ—¶å€™ï¼Œç»éªŒé£é™©ä¼šäº§ç”Ÿè¿‡æ‹Ÿåˆã€‚æ‰€ä»¥éœ€è¦ç»“æ„é£é™©æœ€å°åŒ–(structural risk minimization,SRM),èäº†é˜²æ­¢è¿‡æ‹Ÿåˆ:<br>$$<br>R_{srm}(f)&#x3D;\frac{1}{N}\sum_i L(y_i.f(x_i))+\lambda J(f)<br>$$</p>
<blockquote>
<p>J(f)ä¸ºæ¨¡å‹å¤æ‚åº¦ï¼Œ$\lambda \ge 0$</p>
</blockquote>
<p>ç»“æ„é£é™©å°ï¼Œéœ€è¦ç»éªŒé£é™©ä¸å¤æ‚åº¦åŒæ—¶å°<br>$$<br>min_f\frac{1}{N}\sum_i L(y_i.f(x_i))+\lambda J(f)<br>$$</p>
<h3><span id="regression-loss">Regression Loss</span></h3><h4><span id="l_1-loss-x2f-laplace-loss-x2f-absolute-loss">$l_1$ Loss &#x2F; Laplace Loss &#x2F; Absolute Loss</span></h4><p>$l_1$ &#x3D; $\lvert r \rvert$</p>
<blockquote>
<p>ç¼ºç‚¹ï¼šä¸å¯å¾®åˆ†</p>
</blockquote>
<h4><span id="l_2-loss-x2f-square-loss">$l_2$ Loss &#x2F; Square Loss</span></h4><p>$l_2$ &#x3D; $r^2$</p>
<blockquote>
<p>ç¼ºç‚¹ï¼š$l_2$ å—outlier çš„å½±å“æ¯”$l_1$å½±å“å¤§ï¼Œæ‰€ä»¥ä¸robust</p>
</blockquote>
<h4><span id="huber-loss">Huber Loss</span></h4><blockquote>
<p>robust è€Œä¸”å¯å¾®åˆ† </p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/27695029-4f327793a9d758b6.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Loss å¯¹æ¯”.JPG"></p>
<h3><span id="classification-loss">Classification Loss</span></h3><h4><span id="margin">Margin</span></h4><p>$$1\ if\ y &#x3D; \hat{y}$$<br>$$-1\ if\ y\neq\hat{y}$$</p>
<blockquote>
<p>ä¸å¯å¾®ï¼Œéå‡¸</p>
</blockquote>
<h4><span id="zero-one">Zero-one</span></h4><p>$l_{0-1}&#x3D;1\ if\ m\leq0$ </p>
<blockquote>
<p>m&gt;0 åˆ†ç±»æ­£ç¡®<br>##SVM&#x2F;Hinge<br>$l_{Hinge}&#x3D;max(1-m,0)$<br>##Logistic&#x2F;Log loss<br>$l_{logistic} &#x3D; log(1+e^{-m})$<br>å¯å¾®</p>
</blockquote>
<blockquote>
<p>å¯¹æ¯”</p>
<p><img src="https://upload-images.jianshu.io/upload_images/27695029-6c25b23439b92b7a.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="z_h_l.JPG"></p>
</blockquote>
<h2><span id="grammçŸ©é˜µ">GrammçŸ©é˜µ</span></h2><p>å¦‚æœæœ‰x1,x2,x3,åˆ™:<br>$$<br>\left[<br> \begin{matrix}<br>   x_1\cdot x_1 &amp; x_2\cdot x_1 &amp; x_3\cdot x_1 \<br>   x_1\cdot x_2 &amp; x_2\cdot x_2 &amp; x_3\cdot x_2 \<br>   x_1\cdot x_3 &amp; x_2\cdot x_3 &amp; x_3\cdot x_3<br>  \end{matrix}<br>  \right] \tag{3}<br>$$</p>
<p>ä¸»è¦ç”¨äºKernelè®¡ç®—</p>
<h2><span id="mercers-theorem">Mercerâ€™s Theorem</span></h2><p>ä¸»è¦ç”¨äºåˆ¤åˆ«ï¼Œæ˜¯å¦ä¸ºKernel function</p>
<p>åŠæ­£å®šçŸ©é˜µ(Positive Semidefinite, psd)ï¼š<br>$$<br>X^TMX \geq 0<br>$$<br>with M &#x3D; $R^TR$, and Eigenvalue of M $\geq$ 0</p>
<h2><span id="kernel-trick">Kernel Trick</span></h2><p>ç”¨äºçº¿æ€§ä¸å¯åˆ†çš„æƒ…å†µä¸‹ï¼Œæå‡ç»´åº¦<br>$$<br>&lt;\Phi(x),\Phi(x^{â€˜})&gt; &#x3D; &lt;x,x^{â€˜}&gt;^2<br>$$</p>
<blockquote>
<p>å³æ ¸å‡½æ•°çš„å†…ç§¯ç­‰äºåŸæ¥çš„å†…ç§¯çš„å¹³æ–¹</p>
</blockquote>
<p>çº¿æ€§æ ¸å‡½æ•°ï¼š<br>$$<br>\Phi(x) &#x3D; (x^2,\sqrt2xy,y^2)<br>\<br>x&#x3D;(x_1,y_1),x^{â€˜} &#x3D; (x_2,y_2)<br>\<br>&lt;x,x^{â€˜}&gt;^2&#x3D;(x_1x_2+y_1y_2)^2&#x3D;x_1^2x_2^2+2x_1x_2y_1y_2+y_1y_2^2&#x3D;&lt;\Phi(x),\Phi(x^{â€˜})&gt;<br>$$</p>
<h2><span id="æ°æ£®ä¸ç­‰å¼jensens-inequality">æ°æ£®ä¸ç­‰å¼(Jensenâ€™s inequality)</span></h2><p>æ°æ£®ä¸ç­‰å¼å…¶å®å°±æ˜¯å‡¸å‡½æ•°çš„å®šä¹‰<br>$$<br>tf(x_1)+(1-t)f(x_2)\geq f(tx_1+(1-t)x_2)<br>$$</p>
<p>$$<br>E(f(x)) \geq f(E(x))<br>$$</p>
<h2><span id="å‡¸å‡½æ•°">å‡¸å‡½æ•°</span></h2><p>å‡¸å‡½æ•°çš„å……è¦æ¡ä»¶æ˜¯HessiançŸ©é˜µä¸ºåŠæ­£å®šï¼Œä¸”jacobiançŸ©é˜µä¸º0ï¼Œå³ä¸€é˜¶å¯¼æ•°ä¸º0ã€‚ ä¸€é˜¶å¯¼æ•°ä¸º0è¯´æ˜å…¶ä¸ºä¸€ä¸ªstationary point,äºŒé˜¶å¯¼æ•°ä¸ºé›¶ï¼Œè¯´æ˜æ–œç‡æ˜¯å•è°ƒé€’å¢çš„ã€‚<br>$$<br>f^{â€˜â€™}(x) \geq 0<br>$$</p>
<p><img src="https://img-blog.csdnimg.cn/20181102194631741.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA0MjAyODM=,size_16,color_FFFFFF,t_70" alt="img"></p>
<p>ï¼Œ</p>
<h2><span id="weak-max-min-inequality">Weak Max-Min Inequality</span></h2><p>$$<br>\inf f(w,z_0) \leq f(w_0,z_0) \leq supf(w_0,z)<br>$$</p>
<p>$$<br>d^*&#x3D;sup\ inf\ f(w,z) \leq inf\ sup\ f(w,z)&#x3D;p^*<br>$$</p>
<h2><span id="æ¾å¼›äº’è¡¥complementary-slackness">æ¾å¼›äº’è¡¥ï¼ˆComplementary slacknessï¼‰</span></h2><p>$$<br>p^*&#x3D;d^*&#x3D;f_0(x^*)&#x3D;g(\lambda^*)&#x3D;L(x^*,\lambda^*) \Rightarrow \lambda_i^<em>f_i(x^</em>)&#x3D;0<br>$$</p>
<h2><span id="ä¸¤å¹³è¡Œçº¿è·ç¦»å…¬å¼">ä¸¤å¹³è¡Œçº¿è·ç¦»å…¬å¼</span></h2><p>$$<br>Ax+By&#x3D;C_1\ and\ Ax+By&#x3D;C_2<br>$$</p>
<p>$$<br>Distance &#x3D; \frac{\mid C_1-C_2\mid}{\sqrt{A^2+B^2}}<br>$$</p>
<h2><span id="pdfprobability-density-function">PDF(Probability density function)</span></h2><p><img src="https://upload.wikimedia.org/wikipedia/commons/b/ba/Normalverteilung.PNG" alt="z_h_l.JPG"></p>
<h2><span id="cdfcumulative-distribution-function">CDF(Cumulative distribution function)</span></h2><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Normal_Distribution_CDF.svg/1920px-Normal_Distribution_CDF.svg.png" alt="z_h_l.JPG"></p>
<h2><span id="pmfprobability-mass-function">PMF(probability mass function)</span></h2><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Discrete_probability_distrib.svg/1920px-Discrete_probability_distrib.svg.png" alt="z_h_l.JPG"></p>
<h2><span id="æ³Šæ¾åˆ†å¸ƒpoisson-distribution">æ³Šæ¾åˆ†å¸ƒ(Poisson distribution)</span></h2><p>æ˜¯ç¦»æ•£åˆ†å¸ƒ<br>$$<br>P(X&#x3D;k) &#x3D; \frac{e^{-\lambda}\lambda^k}{k!}<br>$$<br>PMF:</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Poisson_pmf.svg/488px-Poisson_pmf.svg.png" alt="z_h_l.JPG"></p>
<p>CDF:</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Poisson_cdf.svg/1024px-Poisson_cdf.svg.png" alt="z_h_l.JPG"></p>
<h2><span id="variance">Variance</span></h2><p>$$<br>Var(X) &#x3D; {E(X-\mu)^2}\<br>&#x3D;E(X^2)-2E(X)E(X) + E(X)^2\<br>&#x3D;E(X^2)-E(X)^2\<br>E(X^2)&#x3D;\sigma^2+\mu^2<br>$$</p>
<h2><span id="ä¼¯åŠªåˆ©åˆ†å¸ƒå’ŒäºŒé¡¹åˆ†å¸ƒ">ä¼¯åŠªåˆ©åˆ†å¸ƒå’ŒäºŒé¡¹åˆ†å¸ƒ</span></h2><p>äºŒé¡¹åˆ†å¸ƒå°±æ˜¯å¾ˆå¤šæ¬¡ä¼¯åŠªåˆ©åˆ†å¸ƒ</p>
<h2><span id="zåˆ†å¸ƒå’Œtåˆ†å¸ƒ">Zåˆ†å¸ƒå’ŒTåˆ†å¸ƒ</span></h2><p>Tåˆ†å¸ƒç”¨äºå°æ ·æœ¬ï¼ŒZåˆ†å¸ƒç”¨äºå¤§æ ·æœ¬ï¼Œå½“nå¤§äºç­‰äº30æ—¶ï¼ŒZåˆ†å¸ƒå’ŒTåˆ†å¸ƒæ¥è¿‘</p>
<p>Zåˆ†å¸ƒï¼š<br>$$<br>z &#x3D; \frac{x-\mu}{\sigma&#x2F;\sqrt{n}}<br>$$<br>Tåˆ†å¸ƒï¼š<br>$$<br>t&#x3D;\frac{x-\mu}{s&#x2F;\sqrt{n}}\ with\ sæ ·æœ¬æ–¹å·®ï¼š\frac{\sum(x-\mu)}{n-1}<br>$$</p>
<h2><span id="è’™ç‰¹å¡æ´›ç§¯åˆ†">è’™ç‰¹å¡æ´›ç§¯åˆ†</span></h2><p>$$<br>F&#x3D;\frac{1}{N}\sum{\frac{f(x)}{pdf(x)}}<br>$$</p>
<p><img src="https://www.qiujiawei.com/images/2016.8/1.png" alt="z_h_l.JPG"></p>
<h2><span id="åˆ¤åˆ«æ¨¡å‹å’Œç”Ÿæˆæ¨¡å‹">åˆ¤åˆ«æ¨¡å‹å’Œç”Ÿæˆæ¨¡å‹</span></h2><p>äºŒè€…ç›®çš„éƒ½æ˜¯åœ¨ä½¿åéªŒæ¦‚ç‡æœ€å¤§åŒ–ï¼Œåˆ¤åˆ«å¼æ˜¯ç›´æ¥å¯¹åéªŒæ¦‚ç‡å»ºæ¨¡ï¼Œä½†æ˜¯ç”Ÿæˆæ¨¡å‹é€šè¿‡è´å¶æ–¯å®šç†è¿™ä¸€â€œæ¡¥æ¢â€ä½¿é—®é¢˜è½¬åŒ–ä¸ºæ±‚è”åˆæ¦‚ç‡</p>
<p>å‡è®¾æœ‰å››ä¸ªsamplesï¼š </p>
<p><img src="https://pic1.zhimg.com/50/v2-5eb5e035330831cd01d8fbea8d5b51e7_720w.jpg?source=1940ef5c" alt="img"><img src="https://pic1.zhimg.com/80/v2-5eb5e035330831cd01d8fbea8d5b51e7_1440w.jpg?source=1940ef5c" alt="img"></p>
<p>ç”Ÿæˆå¼æ¨¡å‹çš„ä¸–ç•Œæ˜¯è¿™ä¸ªæ ·å­ï¼š</p>
<p><img src="https://pica.zhimg.com/50/v2-b082814755a62fcf676f3d08c70d2d0d_720w.jpg?source=1940ef5c" alt="img"><img src="https://pica.zhimg.com/80/v2-b082814755a62fcf676f3d08c70d2d0d_1440w.jpg?source=1940ef5c" alt="img"><br><img src="https://www.zhihu.com/equation?tex=%5CSigma+P(x,+y)+=+1" alt="[å…¬å¼]"></p>
<p>è€Œåˆ¤å®šå¼æ¨¡å‹çš„ä¸–ç•Œæ˜¯è¿™ä¸ªæ ·å­ï¼š</p>
<p><img src="https://pic2.zhimg.com/50/v2-11f8a39d629e2649146bf12794fe310c_720w.jpg?source=1940ef5c" alt="img"><img src="https://pic2.zhimg.com/80/v2-11f8a39d629e2649146bf12794fe310c_1440w.jpg?source=1940ef5c" alt="img"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Csum_%7By%7D%7BP(y+%7C+x)%7D+=+1+" alt="[å…¬å¼]"></p>
<h2><span id="æå¤§ä¼¼ç„¶ä¼°è®¡mle">æå¤§ä¼¼ç„¶ä¼°è®¡(MLE)</span></h2><p>çŸ¥é“æ•°æ®æ¥æ¨æ±‚æ¨¡å‹å‚æ•°ï¼Œå‡è®¾ä¸çŸ¥é“$\theta$ çš„å…ˆéªŒåˆ†å¸ƒ<br>$$<br>P(X|\theta)&#x3D;\prod\theta^x(1-\theta)^{1-x}<br>$$</p>
<p>$$<br>log(y) &#x3D; \sum xlog\theta+(1-x)(1-\theta)<br>$$</p>
<p>$$<br>d(logy)&#x3D;\frac{\sum x}{\theta}+\frac{\sum 1-x}{1-\theta}&#x3D;0 \<br>\theta &#x3D; \frac{\sum x}{n}<br>$$</p>
<h2><span id="æœ€å¤§åéªŒæ¦‚ç‡-map">æœ€å¤§åéªŒæ¦‚ç‡ (MAP)</span></h2><p>å‡è®¾$\theta$ ç¬¦åˆä¸€å®šçš„å…ˆéªŒåˆ†å¸ƒï¼Œåˆ™åéªŒæ¦‚ç‡ä¸º<br>$$<br>P(\theta|X)&#x3D;\frac{P(X|\theta)P(\theta)}{P(X)}<br>$$<br>P(X)ä¸ºå¸¸æ•°ï¼Œå¯çœç•¥<br>$$<br>log(y)&#x3D;log(P(X|\theta))+log(P(\theta))<br>$$</p>
<p>$$<br>d(logy)&#x3D;\frac{\sum x}{n} + log(P(\theta))&#x3D;0<br>$$</p>
<h2><span id="æ³°å‹’å±•å¼€">æ³°å‹’å±•å¼€</span></h2><p>$$<br>g(x)\approx g(x_0)+ \frac{f^{â€˜}(x_0)}{1!}(x-x_0)+\frac{f^{â€˜â€™}(x_0)}{2!}(x-x_0)<br>$$</p>
<h2><span id="æ¢¯åº¦ä¸‹é™æ³•">æ¢¯åº¦ä¸‹é™æ³•</span></h2><p>$$<br>J(\theta) &#x3D; \frac{1}{2m}\sum_i(y-\sum_j\theta x)^2<br>$$</p>
<p>$$<br>\frac{\delta J(\theta)}{\delta \theta_j} &#x3D; -\frac{1}{m}\sum_i(y-\sum \theta x)x_j<br>$$</p>
<p>$$<br>\theta_{j+1} &#x3D; \theta_j - \frac{\delta J(\theta)}{\delta \theta_j}<br>$$</p>
<h2><span id="ç‰›é¡¿æ³•">ç‰›é¡¿æ³•</span></h2><p>åŸºæœ¬ç‰›é¡¿æ³•æ˜¯ä¸€ç§æ˜¯ç”¨å¯¼æ•°çš„ç®—æ³•ï¼Œå®ƒæ¯ä¸€æ­¥çš„è¿­ä»£æ–¹å‘éƒ½æ˜¯æ²¿ç€å½“å‰ç‚¹å‡½æ•°å€¼ä¸‹é™çš„æ–¹å‘ã€‚<br>    æˆ‘ä»¬ä¸»è¦é›†ä¸­è®¨è®ºåœ¨ä¸€ç»´çš„æƒ…å½¢ï¼Œå¯¹äºä¸€ä¸ªéœ€è¦æ±‚è§£çš„ä¼˜åŒ–å‡½æ•°ï¼Œæ±‚å‡½æ•°çš„æå€¼çš„é—®é¢˜å¯ä»¥è½¬åŒ–ä¸ºæ±‚å¯¼å‡½æ•°ã€‚å¯¹å‡½æ•°è¿›è¡Œæ³°å‹’å±•å¼€åˆ°äºŒé˜¶ï¼Œå¾—åˆ°</p>
<p><img src="http://latex.codecogs.com/gif.latex?f%5Cleft&space;(&space;x&space;%5Cright&space;)=f%5Cleft&space;(&space;x_k&space;%5Cright&space;)+%7Bf%7D%27%5Cleft&space;(&space;x_k&space;%5Cright&space;)%5Cleft&space;(&space;x-x_k&space;%5Cright&space;)+%5Cfrac%7B1%7D%7B2%7D%7Bf%7D%27%27%5Cleft&space;(&space;x_k&space;%5Cright&space;)%5Cleft&space;(&space;x-x_k&space;%5Cright&space;)%5E2" alt="z_h_l.JPG"></p>
<p>å¯¹ä¸Šå¼æ±‚å¯¼å¹¶ä»¤å…¶ä¸º0ï¼Œåˆ™ä¸º</p>
<p><img src="http://latex.codecogs.com/gif.latex?%7Bf%7D%27%5Cleft&space;(&space;x_k&space;%5Cright&space;)+%7Bf%7D%27%27%5Cleft&space;(&space;x_k&space;%5Cright&space;)%5Cleft&space;(&space;x-x_k&space;%5Cright&space;)=0" alt="z_h_l.JPG"></p>
<p>å³å¾—åˆ°</p>
<p><img src="http://latex.codecogs.com/gif.latex?x=x_k-%5Cfrac%7B%7Bf%7D%27%5Cleft&space;(&space;x_k&space;%5Cright&space;)%7D%7B%7Bf%7D%27%27%5Cleft&space;(&space;x_k&space;%5Cright&space;)%7D" alt="z_h_l.JPG"></p>
<p>è¿™å°±æ˜¯ç‰›é¡¿æ³•çš„æ›´æ–°å…¬å¼ã€‚</p>
<h1><span id="æœºå™¨å­¦ä¹ åŸºç¡€">æœºå™¨å­¦ä¹ åŸºç¡€</span></h1><h2><span id="æ— ç›‘ç£å­¦ä¹ ç®—æ³•unsupervised-learning-algorithm">æ— ç›‘ç£å­¦ä¹ ç®—æ³•ï¼ˆunsupervised learning algorithmï¼‰</span></h2><p>è®­ç»ƒå«æœ‰å¾ˆå¤šç‰¹å¾çš„æ•°æ®é›†ï¼Œç„¶åå­¦ä¹ å‡ºè¿™ä¸ªæ•°æ®é›†ä¸Šæœ‰ç”¨çš„ç»“æ„æ€§è´¨ã€‚</p>
<h2><span id="ç›‘ç£å­¦ä¹ ç®—æ³•supervised-learning-algorithm">ç›‘ç£å­¦ä¹ ç®—æ³•ï¼ˆsupervised learning algorithm)</span></h2><p>è®­ç»ƒå«æœ‰å¾ˆå¤šç‰¹å¾çš„æ•°æ®é›†ï¼Œä¸è¿‡æ•°æ®é›†ä¸­çš„æ ·æœ¬éƒ½æœ‰ä¸€ä¸ªæ ‡ç­¾ï¼ˆlabelï¼‰æˆ–ç›®æ ‡ï¼ˆtargetï¼‰ã€‚</p>
<h2><span id="å¼ºåŒ–å­¦ä¹ rein-forcement-learningç®—æ³•">å¼ºåŒ–å­¦ä¹ ï¼ˆrein-forcement learningï¼‰ç®—æ³•</span></h2><p>ä¼šå’Œç¯å¢ƒè¿›è¡Œäº¤äº’ï¼Œæ‰€ä»¥å­¦ä¹ ç³»ç»Ÿå’Œå®ƒçš„è®­ç»ƒè¿‡ç¨‹ä¼šæœ‰åé¦ˆå›è·¯</p>
<h2><span id="è®¾è®¡çŸ©é˜µdesign-matrix">è®¾è®¡çŸ©é˜µï¼ˆdesign matrixï¼‰</span></h2><p>è®¾è®¡çŸ©é˜µçš„æ¯ä¸€è¡ŒåŒ…å«ä¸€ä¸ªä¸åŒçš„æ ·æœ¬ã€‚æ¯ä¸€åˆ—å¯¹åº”ä¸åŒçš„ç‰¹å¾ã€‚</p>
<h2><span id="è®­ç»ƒè¯¯å·®training-error">è®­ç»ƒè¯¯å·®ï¼ˆtraining errorï¼‰</span></h2><p>ä»¥çº¿æ€§å›å½’ä¸ºä¾‹å­:<br>$$<br>\frac{1}{m_{train}}\lVert X_{train}w-y_{train}\rVert_2^2<br>$$</p>
<h2><span id="æµ‹è¯•è¯¯å·®test-error">æµ‹è¯•è¯¯å·®ï¼ˆtest errorï¼‰</span></h2><p>ä»¥çº¿æ€§å›å½’ä¸ºä¾‹å­:</p>
<p>$$<br>\frac{1}{m_{test}}\lVert X_{test}w-y_{test}\rVert_2^2<br>$$</p>
<h2><span id="å¥¥å¡å§†å‰ƒåˆ€-occams-razor">å¥¥å¡å§†å‰ƒåˆ€ Occamâ€™s Razor</span></h2><ul>
<li>If two models correctly predict the data, the one that makes fewer assumptions should be preferred because simplicity is desirable in itself.</li>
<li>If two models correctly predict the data, the one that makes fewer assumptions should be preferred because it is likely to have lower generalization error</li>
</ul>
<h2><span id="vapnik-chervonenkis-ç»´åº¦">Vapnik-Chervonenkis ç»´åº¦</span></h2><p>VCç»´å®šä¹‰ä¸ºè¯¥åˆ†ç±»å™¨èƒ½å¤Ÿåˆ†ç±»çš„è®­ç»ƒæ ·æœ¬çš„æœ€å¤§æ•°ç›®ã€‚å‡è®¾å­˜åœ¨m ä¸ªä¸åŒx ç‚¹çš„è®­ç»ƒé›†ï¼Œåˆ†ç±»å™¨å¯ä»¥ä»»æ„åœ°æ ‡è®°è¯¥m ä¸ªä¸åŒçš„x ç‚¹ï¼ŒVCç»´è¢«å®šä¹‰ä¸ºmçš„æœ€å¤§å¯èƒ½å€¼ã€‚</p>
<p>ç»Ÿè®¡å­¦ä¹ ç†è®ºä¸­æœ€é‡è¦çš„ç»“è®ºé˜è¿°äº†è®­ç»ƒè¯¯å·®å’Œæ³›åŒ–è¯¯å·®ä¹‹é—´å·®å¼‚çš„ä¸Šç•Œéšç€æ¨¡å‹å®¹é‡å¢é•¿è€Œå¢é•¿ï¼Œä½†éšç€è®­ç»ƒæ ·æœ¬å¢å¤šè€Œä¸‹é™</p>
<p><img src="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/model.JPG"></p>
<h2><span id="è´å¶æ–¯è¯¯å·®bayes-error">è´å¶æ–¯è¯¯å·®ï¼ˆBayes errorï¼‰</span></h2><p>ä»é¢„å…ˆçŸ¥é“çš„çœŸå®åˆ†å¸ƒp(x; y) é¢„æµ‹è€Œå‡ºç°çš„è¯¯å·®è¢«ç§°ä¸ºè´å¶æ–¯è¯¯å·®</p>
<h2><span id="æ²¡æœ‰å…è´¹åˆé¤å®šç†no-freelunch-theorem">æ²¡æœ‰å…è´¹åˆé¤å®šç†ï¼ˆno freelunch theoremï¼‰</span></h2><p>åœ¨æŸç§æ„ä¹‰ä¸Šï¼Œæ²¡æœ‰ä¸€ä¸ªæœºå™¨å­¦ä¹ ç®—æ³•æ€»æ˜¯æ¯”å…¶ä»–çš„è¦å¥½ã€‚</p>
<h2><span id="æƒé‡è¡°å‡weight-decay">æƒé‡è¡°å‡ï¼ˆweight decayï¼‰</span></h2><p>ä¿®æ”¹çº¿æ€§å›å½’çš„è®­ç»ƒæ ‡å‡†ã€‚<br>$$<br>J(w) &#x3D; MSE + \lambda w^tw<br>$$<br>å½“$\lambda$éå¸¸å¤§æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å¼ºè¿«æ¨¡å‹å­¦ä¹ åˆ°äº†ä¸€ä¸ªæ²¡æœ‰æ–œç‡çš„å‡½æ•°ã€‚ç”±äºå®ƒåªèƒ½è¡¨ç¤ºä¸€ä¸ªå¸¸æ•°å‡½æ•°ï¼Œæ‰€ä»¥ä¼šå¯¼è‡´æ¬ æ‹Ÿåˆã€‚å–ä¸€ä¸ªé€‚å½“çš„$\lambda$æ—¶ï¼Œå­¦ä¹ ç®—æ³•èƒ½å¤Ÿç”¨ä¸€ä¸ªæ­£å¸¸çš„å½¢çŠ¶æ¥æ¢å¤æ›²ç‡ã€‚å³ä½¿æ¨¡å‹èƒ½å¤Ÿç”¨æ›´å¤æ‚çš„å½¢çŠ¶æ¥æ¥è¡¨ç¤ºå‡½æ•°ï¼Œæƒé‡è¡°å‡é¼“åŠ±ç”¨ä¸€ä¸ªå¸¦æœ‰æ›´å°å‚æ•°çš„æ›´ç®€å•çš„æ¨¡å‹æ¥æè¿°å®ƒã€‚å½“æƒé‡è¡°å‡è¶‹è¿‘äº0ä¼šå¯¼è‡´ä¸¥é‡çš„è¿‡æ‹Ÿåˆ.</p>
<h2><span id="æ­£åˆ™åŒ–regularization">æ­£åˆ™åŒ–ï¼ˆregularizationï¼‰</span></h2><p>æ­£åˆ™åŒ–æ˜¯æŒ‡æˆ‘ä»¬ä¿®æ”¹å­¦ä¹ ç®—æ³•ï¼Œä½¿å…¶é™ä½æ³›åŒ–è¯¯å·®è€Œéè®­ç»ƒè¯¯å·®ã€‚</p>
<p>æ­£åˆ™åŒ–ä¸æ¨¡å‹çš„å¤æ‚åº¦ç›¸å…³ï¼Œæ¨¡å‹è¶Šå¤æ‚ï¼Œæ­£åˆ™åŒ–å€¼å°±è¶Šå¤§ã€‚ç»éªŒæŸå¤± + $\lambda J(\theta)$</p>
<h3><span id="lasso-regularization">Lasso Regularization</span></h3><p>$\lambda \parallel \omega \parallel_1$, where $\parallel \omega \parallel_1 $ &#x3D; $\mid \omega_1 \mid + \mid \omega_2 \mid + \dots+\mid \omega_d \mid$</p>
<h3><span id="ridge-regularization">Ridge Regularization</span></h3><p>$\lambda \parallel \omega \parallel_2^2$, where $\parallel \omega \parallel_1 $ &#x3D; $\omega_1^2 + \omega_2^2 + \dots+\omega_d^2$</p>
<h3><span id="ä¸ºä»€ä¹ˆlasso-æ¯”ridge-æ›´ç¨€ç–-ridgeæ¯”lassoæ›´å¹³æ»‘">ä¸ºä»€ä¹ˆLasso æ¯”Ridge æ›´ç¨€ç–ï¼Œ Ridgeæ¯”Lassoæ›´å¹³æ»‘</span></h3><p><img src="https://pica.zhimg.com/v2-a026e24156e13a1d14c43df26b9bd2a4_r.jpg?source=1940ef5c"></p>
<p><img src="https://pica.zhimg.com/v2-f6edae58134c5a26687c3883af48d5d5_r.jpg?source=1940ef5c"></p>
<p><img src="https://pic3.zhimg.com/v2-3aaa69f70754c469bca5c8e4c3e161db_r.jpg?source=1940ef5c"></p>
<h2><span id="äº¤å‰éªŒè¯">äº¤å‰éªŒè¯</span></h2><p>å°†æ•°æ®é›†åˆ†æˆå›ºå®šçš„è®­ç»ƒé›†å’Œå›ºå®šçš„æµ‹è¯•é›†åï¼Œè‹¥æµ‹è¯•é›†çš„è¯¯å·®å¾ˆå°ï¼Œè¿™å°†æ˜¯æœ‰é—®é¢˜çš„ã€‚è¿™äº›è¿‡ç¨‹æ˜¯åŸºäºåœ¨åŸå§‹æ•°æ®ä¸Šéšæœºé‡‡æ ·æˆ–åˆ†ç¦»å‡ºçš„ä¸åŒæ•°æ®é›†ä¸Šé‡å¤è®­ç»ƒå’Œæµ‹è¯•çš„æƒ³æ³•ã€‚æœ€å¸¸è§çš„æ˜¯k-æŠ˜äº¤å‰éªŒè¯è¿‡ç¨‹ï¼Œå°†æ•°æ®é›†åˆ†æˆk ä¸ª<br>ä¸é‡åˆçš„å­é›†ã€‚æµ‹è¯•è¯¯å·®å¯ä»¥ä¼°è®¡ä¸ºk æ¬¡è®¡ç®—åçš„å¹³å‡æµ‹è¯•è¯¯å·®ã€‚åœ¨ç¬¬i æ¬¡æµ‹è¯•æ—¶ï¼Œæ•°æ®çš„ç¬¬i ä¸ªå­é›†ç”¨äºæµ‹è¯•é›†ï¼Œå…¶ä»–çš„æ•°æ®ç”¨äºè®­ç»ƒé›†ã€‚</p>
<h2><span id="é¢„æµ‹è¯¯å·®measures-prediction-errormse">é¢„æµ‹è¯¯å·®ï¼ˆmeasures prediction error,MSEï¼‰</span></h2><p>$$<br>MSE &#x3D; E[(\hat \theta-\theta)^2]&#x3D;Bias(\hat \theta)^2+Var(\hat \theta)&#x3D;E[\hat \theta-\theta]^2+E[(\hat \theta-E[\theta])^2]<br>$$</p>
<p>ç”¨MSEåº¦é‡æ³›åŒ–è¯¯å·®ï¼ˆåå·®å’Œæ–¹å·®å¯¹äºæ³›åŒ–è¯¯å·®éƒ½æ˜¯æœ‰æ„ä¹‰çš„ï¼‰æ—¶ï¼Œå¢åŠ å®¹é‡ä¼šå¢åŠ æ–¹å·®ï¼Œé™ä½åå·®ï¼Œå³Bias,Variance Tradoff. å½“æ¨¡å‹å¤æ‚æ—¶ï¼Œbiaså¾€å¾€æ—¶æ¯”è¾ƒå°çš„ï¼Œè¿™æ—¶å€™è¯¯å·®ä¸»è¦æ¥æºäºVarianceã€‚åä¹‹ï¼Œæ¨¡å‹æ¯”è¾ƒç®€å•ï¼ŒBiasè¾ƒå¤§ï¼ŒVarianceè¾ƒå°ã€‚Biasä»£è¡¨çš„æ˜¯æ¨¡å‹çš„é¢„æµ‹å‡†ç¡®æ€§ï¼ŒVarianceä»£è¡¨çš„æ˜¯æ¨¡å‹å¯¹ç‰¹å®šæ•°æ®é›†çš„æ•æ„Ÿç¨‹åº¦</p>
<p><img src="https://raw.githubusercontent.com/PPPPan/PPPPan.github.io/master/images/MSE.JPG"></p>
<h2><span id="underfitting-overfitting">Underfitting, Overfitting</span></h2><p>Underfitting: High bias.</p>
<ol>
<li>æ¨¡å‹è¿‡äºç®€å•</li>
<li>ç‰¹å¾å’Œé¢„æµ‹ç»“æœç›¸å…³æ€§å¤ªä½ï¼Œæ— æ³•æä¾›æœ‰ä»·å€¼çš„ä¿¡æ¯</li>
</ol>
<p>Overfitting: High variance</p>
<ol>
<li>æ¨¡å‹è¿‡äºå¤æ‚</li>
<li>ç‰¹å¾å¤ªå¤šï¼Œè®­ç»ƒæ•°æ®é›†å¤ªå°</li>
</ol>
<p>è§£å†³overfitting:</p>
<ol>
<li>é€‰æ‹©ç®€å•æ¨¡å‹</li>
<li>é™ä½æ•°æ®ç»´åº¦</li>
<li>å¢åŠ æ•°æ®é‡</li>
<li>Regularization,å…¶å®ä¹Ÿæ˜¯åœ¨æ§åˆ¶å¤æ‚åº¦ï¼Œå› ä¸ºL1å’ŒL2æ˜¯ä¸æ¨¡å‹å¤æ‚åº¦ç›¸å…³çš„</li>
</ol>
<h2><span id="æ„ŸçŸ¥æœºperceptron">æ„ŸçŸ¥æœº(Perceptron)</span></h2><p>ä¸ºäºŒé¡¹çº¿æ€§åˆ†ç±»æ¨¡å‹<br>$$<br>f(x)&#x3D;sign(wx+b)<br>$$</p>
<blockquote>
<p>+1 x$\ge$ 0</p>
<p>-1 x&lt;0</p>
</blockquote>
<p>ä»»ä¸€ç‚¹$x_0$åˆ°è¶…å¹³é¢Sçš„è·ç¦»:<br>$$<br>\frac{1}{\lVert w \rVert}|wx_0+b|<br>$$<br>å¯¹äºé”™è¯¯åˆ†ç±»çš„ç‚¹:<br>$$<br>-\frac{1}{\lVert w \rVert}y_i(wx_0+b)<br>$$<br>æ‰€æœ‰é”™è¯¯ç‚¹åˆ°è¶…å¹³é¢Sçš„æ€»è·ç¦»:<br>$$<br>-\frac{1}{\lVert w \rVert}\sum_xy_i(wx_0+b)<br>$$<br>æŸå¤±å‡½æ•°:<br>$$<br>L(w,b) &#x3D; -\sum_i y_i(wx_i+b)<br>$$</p>
<blockquote>
<p>$\lVert w \rVert$ &#x3D; 1</p>
</blockquote>
<p>å³æ±‚æŸå¤±å‡½æ•°çš„æœ€å°å€¼:<br>$$<br>min_{w,b}L(w,b) &#x3D; -\sum_i y_i(wx_i+b)<br>$$<br>æ„ŸçŸ¥æœºæµç¨‹:</p>
<ol>
<li><p>é€‰å– w0&#x3D;0,b0&#x3D;0</p>
</li>
<li><p>é€‰æ‹©ç¬¬ä¸€ä¸ªç‚¹å¸¦å…¥ï¼Œå¾—åˆ°$sign(wx_i+b)(wx_i+b)$</p>
</li>
<li><p>if $sign(wx_i+b)(wx_i+b) \le 0$</p>
<ol>
<li>w &#x3D; w+y*x</li>
<li>b&#x3D;b+y</li>
</ol>
</li>
<li><p>è½¬è‡³2ï¼ŒçŸ¥é“æ²¡æœ‰é”™è¯¯åˆ†ç±»ç‚¹</p>
</li>
</ol>
<p><strong>æ„ŸçŸ¥æœºçš„å¯¹å¶å½¢å¼:</strong></p>
<p>å°†æ¨¡å‹æ”¹å†™ä¸º:<br>$$<br>L(w,b) &#x3D; y_i(\sum_j \alpha_j y_j x_j x_i+b)<br>$$</p>
<h2><span id="ç›‘ç£å­¦ä¹ ">ç›‘ç£å­¦ä¹ </span></h2><h3><span id="é€»è¾‘å›å½’logistic-regression">é€»è¾‘å›å½’ï¼ˆlogistic regressionï¼‰</span></h3><p>è¯¥æ¨¡å‹ç”¨äºåˆ†ç±»è€Œéå›å½’ã€‚logistic sigmoid å‡½æ•°ï¼Œ åˆ†ä¸ºä¸¤ç±»ã€‚</p>
<h3><span id="æ”¯æŒå‘é‡æœºsupport-vector-machine-svm">æ”¯æŒå‘é‡æœºï¼ˆsupport vector machine, SVM)</span></h3><p>åŸºäºçº¿æ€§å‡½æ•°$w^Tx+b$ï¼Œå½“ä¸ºæ­£æ—¶ï¼Œæ”¯æŒå‘é‡æœºé¢„æµ‹å±äºæ­£ç±»ã€‚ä¸ºè´Ÿæ•°æ—¶å€™ï¼Œæ”¯æŒå‘é‡æœºé¢„æµ‹å±äºè´Ÿç±»ã€‚</p>
<p>æ”¯æŒå‘é‡æœºä¸­çš„çº¿æ€§å‡½æ•°å¯ä»¥é‡å†™ä¸º:<br>$$<br>w^Tx+b&#x3D;b+\sum_i \alpha_i x^Tx^{(i)}<br>$$</p>
<blockquote>
<p>$x^{(i)}$æ˜¯è®­ç»ƒæ ·æœ¬,$\alpha$æ˜¯ç³»æ•°å‘é‡</p>
</blockquote>
<p>æˆ‘ä»¬å°†x æ›¿æ¢ä¸ºç‰¹å¾å‡½æ•°Ï•(x) çš„è¾“å‡ºï¼Œç‚¹ç§¯æ›¿æ¢ä¸ºè¢«ç§°ä¸º<strong>æ ¸å‡½æ•°ï¼ˆkernel functionï¼‰</strong>çš„å‡½æ•°</p>
<p>k(x, $x^{(i)}$) &#x3D; Ï•(x) Ï•($x^{(i)}$)ã€‚<br>$$<br>f(x)&#x3D;b+\sum_i \alpha_i k(x,x^{(i)})<br>$$<br>æ ¸æŠ€å·§ååˆ†å¼ºå¤§æœ‰ä¸¤ä¸ªåŸå› ã€‚é¦–å…ˆï¼Œå®ƒä½¿æˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨ä¿è¯æœ‰æ•ˆæ”¶æ•›çš„å‡¸ä¼˜åŒ–æŠ€æœ¯æ¥å­¦ä¹ éçº¿æ€§æ¨¡å‹ï¼ˆå…³äºx çš„å‡½æ•°ï¼‰ã€‚è¿™æ˜¯å¯èƒ½çš„ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥è®¤ä¸ºÏ• æ˜¯å›ºå®šçš„ï¼Œä»…ä¼˜åŒ–$\alpha$ï¼Œå³ä¼˜åŒ–ç®—æ³•å¯ä»¥å°†å†³ç­–å‡½æ•°è§†ä¸ºä¸åŒç©ºé—´ä¸­çš„çº¿æ€§å‡½æ•°ã€‚å…¶äºŒï¼Œæ ¸å‡½æ•°k çš„å®ç°æ–¹æ³•é€šå¸¸æœ‰æ¯”ç›´æ¥æ„å»ºÏ•(x) å†ç®—ç‚¹ç§¯é«˜æ•ˆå¾ˆå¤šã€‚</p>
<h3><span id="å†³ç­–æ ‘">å†³ç­–æ ‘</span></h3><p>å¸¸ç”¨çš„å†³ç­–æ ‘æœ‰ID3ï¼ŒC4.5å’ŒCARTï¼ˆClassification And Regression Treeï¼‰ï¼ŒCARTçš„åˆ†ç±»æ•ˆæœä¸€èˆ¬ä¼˜äºå…¶ä»–å†³ç­–æ ‘ã€‚</p>
<p><strong>ID3: ä¿¡æ¯å¢ç›Šæ¥è¿›è¡Œå†³ç­–æ ‘çš„åˆ’åˆ†å±æ€§é€‰æ‹©æ¥å†³å®šé‚£ä¸ªåšçˆ¶èŠ‚ç‚¹ï¼Œé‚£ä¸ªèŠ‚ç‚¹éœ€è¦åˆ†è£‚ã€‚å¯¹äºä¸€ç»„æ•°æ®ï¼Œä¿¡æ¯å¢ç›Šè¶Šå¤§è¯´æ˜åˆ†ç±»ç»“æœè¶Šå¥½</strong></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/9c16e9482a860b7f354bcd8a4d5c418e.png" alt="avatar"></p>
<ol>
<li>è®¡ç®—æ€»ä½“D</li>
<li>è®¡ç®—ä¿¡æ¯ç†µ, å³æ€»ä½“çš„å‡å»ç‰¹å¾çš„ï¼Œå¦‚æœä¿¡æ¯ç†µæ¯”è¾ƒå¤§ï¼Œåˆ™è¯´æ˜æ¬¡ç‰¹å¾æ›´ç¨³å®š</li>
<li>è®¡ç®—ä¿¡æ¯å¢ç›Šï¼Œæ‰¾å‡ºæœ€å¤§å€¼ä¸ºä¸‹ä¸ªèŠ‚ç‚¹</li>
</ol>
<p>ç¼ºç‚¹ï¼šID3ç®—æ³•ä¼šå»é€‰æ‹©å­ç±»åˆ«å¤šçš„ç‰¹å¾ï¼Œå› ä¸ºè¿™æ ·åˆ†è£‚å‡ºæ¥çš„ç»“æœä¼šæ›´çº¯ï¼Œç†µä¼šæ›´å°ï¼Œè¿™æœ‰åäºæˆ‘ä»¬çš„åˆè¡·ï¼Œæˆ‘ä»¬è¦çš„çº¯ä¸æ˜¯æƒ³é€šè¿‡è®©å®ƒåˆ†ç±»åˆ†çš„æ›´ç»†ï¼Œäº§ç”Ÿè¿‡æ‹Ÿåˆ</p>
<p><strong>c4.5å¯¹ID3è¿›è¡Œäº†æ”¹è¿›ï¼Œå› ä¸ºID3ä¼šè¶Šåˆ†è¶Šç»†ï¼Œå¯èƒ½ä¼šé€ æˆoverfittingçš„æƒ…å†µC4.5ä¸­ï¼Œä¼˜åŒ–é¡¹è¦é™¤ä»¥åˆ†å‰²å¤ªç»†çš„ä»£ä»·ï¼Œè¿™ä¸ªæ¯”å€¼å«åšä¿¡æ¯å¢ç›Šç‡ï¼Œæ˜¾ç„¶åˆ†å‰²å¤ªç»†åˆ†æ¯å¢åŠ ï¼Œ<u>ä¿¡æ¯å¢ç›Šç‡</u>ä¼šé™ä½ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œå…¶ä»–çš„åŸç†å’ŒID3ç›¸åŒã€‚</strong></p>
<ol>
<li>è®¡ç®—ç±»åˆ«ä¿¡æ¯ç†µï¼Œå³æ€»ä½“çš„ï¼Œä¸åˆ†å±æ€§çš„</li>
</ol>
<img src="https://img-blog.csdn.net/20160611221836609?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="avatar" style="zoom:150%;">

<p>9ä¸ªå–æ ·ä¸ºæ­£ï¼Œ5ä¸ªä¸ºè´Ÿ</p>
<ol start="2">
<li><p>è®¡ç®—å„ä¸ªç±»åˆ«çš„ä¿¡æ¯ç†µï¼Œä¿¡æ¯ç†µæ˜¯æ¡ä»¶ç†µï¼Œæ¯”å¦‚åœ¨å¤©æ°”ä¸ºé˜´çš„æ—¶å€™çš„æ­£è´Ÿæ€§ã€‚ä¸ç†µä¸åŒçš„æ˜¯ï¼Œç†µç›´æ¥è®¡ç®—å¤©æ°”è¿™ä¸€å±æ€§ï¼Œè€Œä¸å»è®¡ç®—å±æ€§ä¸‹çš„ç±»åˆ«ã€‚</p>
<p><img src="https://img-blog.csdn.net/20160611221842349?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="avatar"></p>
</li>
<li><p>è®¡ç®—ä¿¡æ¯å¢ç›Šï¼Œä¿¡æ¯å¢ç›Š(Gain) &#x3D; æ€»ä½“ç†µ(H) - æ¡ä»¶ç†µ(Info)ã€‚å¦‚æœä¸€ä¸ªå±æ€§çš„ä¿¡æ¯å¢ç›Šè¶Šå¤§ï¼Œå°±è¡¨ç¤ºç”¨è¿™ä¸ªå±æ€§è¿›è¡Œæ ·æœ¬åˆ’åˆ†å¯ä»¥æ›´å¥½çš„å‡å°‘åˆ’åˆ†åæ ·æœ¬çš„ä¸ç¡®å®šæ€§ï¼Œå½“ç„¶ï¼Œé€‰æ‹©è¯¥å±æ€§å°±å¯ä»¥æ›´å¿«æ›´å¥½åœ°å®Œæˆæˆ‘ä»¬çš„åˆ†ç±»ç›®æ ‡</p>
<p><img src="https://img-blog.csdn.net/20160611221847422?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="avatar"></p>
</li>
<li><p>ä½†æ˜¯æˆ‘ä»¬å‡è®¾è¿™æ ·çš„æƒ…å†µï¼Œæ¯ä¸ªå±æ€§ä¸­æ¯ç§ç±»åˆ«éƒ½åªæœ‰ä¸€ä¸ªæ ·æœ¬ï¼Œé‚£è¿™æ ·å±æ€§ä¿¡æ¯ç†µå°±ç­‰äºé›¶ï¼Œæ ¹æ®ä¿¡æ¯å¢ç›Šå°±æ— æ³•é€‰æ‹©å‡ºæœ‰æ•ˆåˆ†ç±»ç‰¹å¾ã€‚æ‰€ä»¥ï¼ŒC4.5é€‰æ‹©ä½¿ç”¨ä¿¡æ¯å¢ç›Šç‡å¯¹ID3è¿›è¡Œæ”¹è¿›ï¼Œè¿™æ˜¯ID3çš„å±€é™æ€§ï¼Œå³ç±»åˆ«åˆ†çš„å¤ªç»†ï¼Œäº§ç”Ÿoverfitting</p>
</li>
<li><p>è®¡ç®—ç±»åˆ«çš„ç†µ</p>
<p><img src="https://img-blog.csdn.net/20160611221851021?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="avatar"></p>
</li>
<li><p>è®¡ç®—ä¿¡æ¯å¢ç›Šç‡ï¼Œï¼ˆä¸‹é¢å†™é”™äº†ã€‚ã€‚åº”è¯¥æ˜¯IGR &#x3D; Gain &#x2F; H ï¼‰</p>
<img src="https://img-blog.csdn.net/20160611222004158?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="avatar" style="zoom:200%;"></li>
</ol>
<p>$$<br>IGR &#x3D; \frac{H(D)-Info(ç±»åˆ«)}{H(ç±»åˆ«)}&#x3D;\frac{Gain}{H}<br>$$</p>
<ol start="7">
<li>ä¿¡æ¯å¢ç›Šç‡è¶Šé«˜è¶Šå¥½ï¼Œå‡å°‘å› ç‰¹å¾å€¼å¤šå¯¼è‡´ä¿¡æ¯å¢ç›Šå¤§çš„é—®é¢˜ã€‚</li>
</ol>
<p><img src="https://img-blog.csdn.net/20160611211339152?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="avatar"></p>
<p><strong>ID3å’ŒC4.5ç®—æ³•ï¼Œåªèƒ½å¤„ç†åˆ†ç±»ä¸èƒ½å¤„ç†å›å½’ã€‚è€ŒCARTï¼ˆclassification and regression treeï¼‰åˆ†ç±»å›å½’æ ‘ç®—æ³•ï¼Œæ—¢å¯ç”¨äºåˆ†ç±»ä¹Ÿå¯ç”¨äºå›å½’ã€‚</strong></p>
<p><strong>CARTåˆ†ç±»æ ‘ç®—æ³•ä½¿ç”¨åŸºå°¼ç³»æ•°é€‰æ‹©ç‰¹å¾</strong>ï¼ŒåŸºå°¼ç³»æ•°ä»£è¡¨äº†æ¨¡å‹çš„ä¸çº¯åº¦ï¼Œ<strong>åŸºå°¼ç³»æ•°è¶Šå°ï¼Œä¸çº¯åº¦è¶Šä½ï¼Œç‰¹å¾è¶Šå¥½</strong>ã€‚</p>
<p>æ•°æ®é›†Dçš„çº¯åº¦å¯ç”¨åŸºå°¼å€¼æ¥åº¦é‡ï¼š</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7DGini(D)&=%5Csum_%7Bi=1%7D%5E%7Bn%7D%7Bp(x_i)*(1-p(x_i))%7D+%5C%5C&=1-%5Csum_%7Bi=1%7D%5E%7Bn%7D%7B%7Bp(x_i)%7D%5E2%7D%5Cend%7Baligned%7D++%5C%5C" alt="avatar"></p>
<h3><span id="knn">KNN</span></h3><p>è¾“å…¥å¸¦æ ‡ç­¾çš„æ•°æ®è®­ç»ƒï¼Œç„¶åç»™æ–°è¾“å…¥çš„æ•°æ®ä¸å·²çŸ¥æ•°æ®æ¯”å¯¹ï¼Œæ‰¾å‡ºå‰kä¸ªæœ€è¿‘çš„æ•°æ®ï¼Œåœ¨è¿™kä¸ªç›¸è¿‘çš„æ•°æ®ä¸­ï¼Œç»™æ–°è¾“å…¥çš„æ•°æ®å¡«ä¸Šæœ€æ¥è¿‘çš„æ ‡ç­¾ã€‚</p>
<ol>
<li>å‡è®¾æœ‰ä¸€ä¸ªå¸¦æœ‰æ ‡ç­¾çš„æ ·æœ¬æ•°æ®é›†ï¼ˆè®­ç»ƒæ ·æœ¬é›†ï¼‰ï¼Œå…¶ä¸­åŒ…å«æ¯æ¡æ•°æ®ä¸æ‰€å±åˆ†ç±»çš„å¯¹åº”å…³ç³»ã€‚</li>
<li>è¾“å…¥æ²¡æœ‰æ ‡ç­¾çš„æ–°æ•°æ®åï¼Œå°†æ–°æ•°æ®çš„æ¯ä¸ªç‰¹å¾ä¸æ ·æœ¬é›†ä¸­æ•°æ®å¯¹åº”çš„ç‰¹å¾è¿›è¡Œæ¯”è¾ƒã€‚<ol>
<li>è®¡ç®—æ–°æ•°æ®ä¸æ ·æœ¬æ•°æ®é›†ä¸­æ¯æ¡æ•°æ®çš„è·ç¦»ã€‚</li>
<li>å¯¹æ±‚å¾—çš„æ‰€æœ‰è·ç¦»è¿›è¡Œæ’åºï¼ˆä»å°åˆ°å¤§ï¼Œè¶Šå°è¡¨ç¤ºè¶Šç›¸ä¼¼ï¼‰ã€‚</li>
<li>å–å‰ k ï¼ˆk ä¸€èˆ¬å°äºç­‰äº 20 ï¼‰ä¸ªæ ·æœ¬æ•°æ®å¯¹åº”çš„åˆ†ç±»æ ‡ç­¾ã€‚</li>
</ol>
</li>
<li>æ±‚ k ä¸ªæ•°æ®ä¸­å‡ºç°æ¬¡æ•°æœ€å¤šçš„åˆ†ç±»æ ‡ç­¾ä½œä¸ºæ–°æ•°æ®çš„åˆ†ç±»ã€‚</li>
</ol>
<h2><span id="k-mean-ç®—æ³•">K Mean ç®—æ³•</span></h2><ul>
<li>éšæœºé€‰Kä¸ªå€¼ä½œä¸ºkä¸ªèšç±»çš„å¹³å‡å€¼</li>
<li>è®²æ¯ä¸ªæ ·æœ¬ä¸è¿™å‡ ä¸ªå‡å€¼ä½œè·ç¦»ï¼Œå°†å…¶å½’ä¸ºæœ€è¿‘çš„ç±»</li>
<li>å¾—åˆ°æ–°çš„ä¸‰ä¸ªèšç±»ï¼Œå†æ±‚å‡å€¼</li>
<li>å†é‡å¤ï¼Œç›´è‡³æ”¶æ•›(mean ä¸å‘ç”Ÿå˜åŒ–)</li>
</ul>
<h2><span id="emç®—æ³•">EMç®—æ³•</span></h2><p>ç”¨äºæ¦‚ç‡æ¨¡å‹ä¸­å«æœ‰è§‚æµ‹å˜é‡(observable variable),ä»¥åŠéšå˜é‡(latent variable).</p>
<p>ä¸»è¦åˆ†ä¸ºä¸¤éƒ¨åˆ†:</p>
<ul>
<li>Eéƒ¨åˆ†ï¼Œæ±‚æœŸæœ› Expectation</li>
<li>Méƒ¨åˆ†ï¼Œæ±‚æå¤§Maximization</li>
</ul>
<p>æ‰€ä»¥ç§°ä¸ºæœŸæœ›æå¤§ç®—æ³•ã€‚</p>
<p>å‡è®¾æˆ‘ä»¬æœ‰ä¸¤æšç¡¬å¸ï¼ŒAä¸B</p>
<p>ä½†æ˜¯æˆ‘ä»¬åœ¨æŠ•æ·çš„è¿‡ç¨‹ä¸­ä¸è®°å½•ç¡¬å¸çš„ç±»å‹ï¼Œè€Œæ˜¯ç¡¬å¸çš„æ­£åé¢ã€‚é‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•æ±‚Aä¸Bå„è‡ªçš„æ¦‚ç‡å‘¢ã€‚</p>
<p>é¦–å…ˆå‡è®¾Açš„æ¦‚ç‡ä¸º0.6ï¼ŒBçš„æ¦‚ç‡ä¸º0.5</p>
<p>åˆ™Açš„æ¦‚ç‡ä¸º:<br>$$<br>P_A &#x3D; \frac{0.6^5 0.4^5}{(0.6^5 0.4^5)+(0.5^50.5^5)} &#x3D; 0.45<br>$$</p>
<h2><span id="bootstrap-é‡‡æ ·æ³•">bootstrap é‡‡æ ·æ³•</span></h2><p>å³æœ‰æ”¾å›çš„é‡‡æ ·æ–¹æ³•ã€‚</p>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2fe7849758309b19fa49cad2f5e214fb4fbb8044" alt="avatar"></p>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e76702c87ce1c681ed1da8213125963524ca0ee6" alt="avatar"></p>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5decdfc7edb14bc3f4dd541d39559ea9a3088f61" alt="avatar"><br>$$<br>\frac{1}{e}&#x3D;lim(1-\frac{1}{n})^n<br>$$<br>åˆ™ï¼Œä»æ¥æ²¡å–åˆ°çš„æ¦‚ç‡ä¸º0.368ï¼Œå–åˆ°çš„æ¦‚ç‡ä¸º0.632</p>
<h2><span id="çº¿æ€§å›å½’">çº¿æ€§å›å½’</span></h2><p>ä¼˜åŒ–æœ€å°è¯¯å·®<br>$$<br>\frac{1}{2}min\sum{(y_i-w^Tx_i)^2} &#x3D; \frac{1}{2}(y-Xw)^T(y-Xw)<br>$$<br>ordinary least squares or OLS solution:</p>
<p>D is small, N&lt;1000<br>$$<br>w_{OLS} &#x3D; (X^TX)^{-1}X^Ty<br>$$</p>
<h2><span id="éšæœºæ£®æ—">éšæœºæ£®æ—</span></h2><p>ä¸ºbaggingä¸ºæ€æƒ³çš„é›†æˆå­¦ä¹ æ–¹æ³•ï¼Œåˆ©ç”¨å¾ˆå¤šå¼±åˆ†ç±»å™¨ï¼Œç„¶åç»è¿‡ä¸€å®šçš„ç»“åˆåŸç†ï¼Œè€Œå¾—åˆ°å¼ºåˆ†ç±»å™¨çš„ç®—æ³•ã€‚</p>
<p>å¼±åˆ†ç±»å™¨ï¼š</p>
<ul>
<li>å…·æœ‰è¾ƒä½çš„åˆ†ç±»èƒ½åŠ›ï¼Œä½†æ˜¯æ¯”ä¹±çŒœå¼º</li>
<li>åˆ†ç±»å™¨ä¹‹é—´å­˜åœ¨å·®å¼‚æ€§</li>
</ul>
<p>ä½¿ç”¨bootstrapé‡‡æ ·åˆ™ï¼Œä»æ¥æ²¡å–åˆ°çš„æ¦‚ç‡ä¸º0.368ï¼Œå–åˆ°çš„æ¦‚ç‡ä¸º0.632ã€‚</p>
<p>åœ¨å¯¹é¢„æµ‹è¾“å‡ºè¿›è¡Œç»“åˆæ—¶ï¼ŒBaggingé€šå¸¸<strong>å¯¹åˆ†ç±»ä»»åŠ¡ä½¿ç”¨ç®€å•æŠ•ç¥¨æ³•</strong>ï¼Œ<strong>å¯¹å›å½’ä»»åŠ¡ä½¿ç”¨ç®€å•å¹³å‡æ³•</strong></p>
<h2><span id="boosting-and-bagging">Boosting and bagging</span></h2><p>Boostingä¸»è¦å…³æ³¨é™ä½åå·®ï¼Œå› æ­¤Boostingèƒ½åŸºäºæ³›åŒ–æ€§èƒ½ç›¸å½“å¼±çš„å­¦ä¹ å™¨æ„å»ºå‡ºå¾ˆå¼ºçš„é›†æˆï¼›Baggingä¸»è¦å…³æ³¨é™ä½æ–¹å·®ï¼Œå› æ­¤å®ƒåœ¨ä¸å‰ªæçš„å†³ç­–æ ‘ã€ç¥ç»ç½‘ç»œç­‰å­¦ä¹ å™¨ä¸Šæ•ˆç”¨æ›´ä¸ºæ˜æ˜¾ã€‚</p>
<h2><span id="xgboost">XGBoost</span></h2><p>å¯¹æ¯”åŸç®—æ³•GBDTï¼ŒXGBoostä¸»è¦ä»ä¸‹é¢ä¸‰ä¸ªæ–¹é¢åšäº†ä¼˜åŒ–ï¼š</p>
<ul>
<li><p>ä¸€æ˜¯ç®—æ³•æœ¬èº«çš„ä¼˜åŒ–ï¼šåœ¨ç®—æ³•çš„å¼±å­¦ä¹ å™¨æ¨¡å‹é€‰æ‹©ä¸Šï¼Œå¯¹æ¯”GBDTåªæ”¯æŒå†³ç­–æ ‘ï¼Œè¿˜å¯ä»¥ç›´æ¥å¾ˆå¤šå…¶ä»–çš„å¼±å­¦ä¹ å™¨ã€‚åœ¨ç®—æ³•çš„æŸå¤±å‡½æ•°ä¸Šï¼Œé™¤äº†æœ¬èº«çš„æŸå¤±ï¼Œè¿˜åŠ ä¸Šäº†æ­£åˆ™åŒ–éƒ¨åˆ†ã€‚åœ¨ç®—æ³•çš„ä¼˜åŒ–æ–¹å¼ä¸Šï¼ŒGBDTçš„æŸå¤±å‡½æ•°åªå¯¹è¯¯å·®éƒ¨åˆ†åšè´Ÿæ¢¯åº¦ï¼ˆä¸€é˜¶æ³°å‹’ï¼‰å±•å¼€ï¼Œè€ŒXGBoostæŸå¤±å‡½æ•°å¯¹è¯¯å·®éƒ¨åˆ†åšäºŒé˜¶æ³°å‹’å±•å¼€ï¼Œæ›´åŠ å‡†ç¡®ã€‚ç®—æ³•æœ¬èº«çš„ä¼˜åŒ–æ˜¯æˆ‘ä»¬åé¢è®¨è®ºçš„é‡ç‚¹ã€‚</p>
</li>
<li><p>äºŒæ˜¯ç®—æ³•è¿è¡Œæ•ˆç‡çš„ä¼˜åŒ–ï¼šå¯¹æ¯ä¸ªå¼±å­¦ä¹ å™¨ï¼Œæ¯”å¦‚å†³ç­–æ ‘å»ºç«‹çš„è¿‡ç¨‹åšå¹¶è¡Œé€‰æ‹©ï¼Œæ‰¾åˆ°åˆé€‚çš„å­æ ‘åˆ†è£‚ç‰¹å¾å’Œç‰¹å¾å€¼ã€‚åœ¨å¹¶è¡Œé€‰æ‹©ä¹‹å‰ï¼Œå…ˆå¯¹æ‰€æœ‰çš„ç‰¹å¾çš„å€¼è¿›è¡Œæ’åºåˆ†ç»„ï¼Œæ–¹ä¾¿å‰é¢è¯´çš„å¹¶è¡Œé€‰æ‹©ã€‚å¯¹åˆ†ç»„çš„ç‰¹å¾ï¼Œé€‰æ‹©åˆé€‚çš„åˆ†ç»„å¤§å°ï¼Œä½¿ç”¨CPUç¼“å­˜è¿›è¡Œè¯»å–åŠ é€Ÿã€‚å°†å„ä¸ªåˆ†ç»„ä¿å­˜åˆ°å¤šä¸ªç¡¬ç›˜ä»¥æé«˜IOé€Ÿåº¦ã€‚</p>
</li>
<li><p>ä¸‰æ˜¯ç®—æ³•å¥å£®æ€§çš„ä¼˜åŒ–ï¼šå¯¹äºç¼ºå¤±å€¼çš„ç‰¹å¾ï¼Œé€šè¿‡æšä¸¾æ‰€æœ‰ç¼ºå¤±å€¼åœ¨å½“å‰èŠ‚ç‚¹æ˜¯è¿›å…¥å·¦å­æ ‘è¿˜æ˜¯å³å­æ ‘æ¥å†³å®šç¼ºå¤±å€¼çš„å¤„ç†æ–¹å¼ã€‚ç®—æ³•æœ¬èº«åŠ å…¥äº†L1å’ŒL2æ­£åˆ™åŒ–é¡¹ï¼Œå¯ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæ³›åŒ–èƒ½åŠ›æ›´å¼ºã€‚</p>
</li>
</ul>
<p>åœ¨GBDTæŸå¤±å‡½æ•°L(y,ftâˆ’1(x)+ht(x))L(y,ftâˆ’1(x)+ht(x))çš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬åŠ å…¥æ­£åˆ™åŒ–é¡¹å¦‚ä¸‹ï¼š<br>$$<br>Î©(ht)&#x3D;Î³J+Î»2âˆ‘_{j&#x3D;1}^Jw^2_{tj}<br>$$</p>
<h2><span id="local-linear-embedding-lle">Local Linear Embedding (LLE)</span></h2><ol>
<li>æ ¹æ®æ¬§å‡ é‡Œå¾—è·ç¦»ï¼Œé€‰æ‹©Kä¸ªneighbor</li>
<li>$Cost &#x3D; (X-wX_{neighbor})(X-wX_{neighbor})^T, \sum w &#x3D; 1,å¦‚æœä¸æ˜¯é‚»å±…åˆ™w_j&#x3D;0$ -&gt; $Cost&#x3D;w^TCw,C&#x3D;(X-X_{neighbor})(X-X_{neighbor})$</li>
<li>ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•-&gt; æ±‚å‡º$2wC-\lambda&#x3D;0$  -&gt; $wç­‰ä»·äºC^{-1}1$</li>
<li>ç„¶åæ˜ å°„å›ä½ç»´ï¼ŒåŒæ ·ä¿æŒç›¸åŒçš„å…³ç³»ï¼Œ $(Y-wY)^T(Y-wY)-&gt;Y^T(1-w)^T(1-w)Y$ , æˆ‘ä»¬è®¾å®šï¼Œ$Y^TY&#x3D;1, \sum Y &#x3D;0$ ,æ”¹å†™ä¸ºï¼Œ$Y^TMY$ </li>
<li>ç„¶åæ‹‰æ ¼æœ—æ—¥æ±‚æ¢¯åº¦ï¼Œ$2YM&#x3D;2\lambda Y$, æ‰€ä»¥æ˜ å°„çš„æ–°åæ ‡ä¸ºMçš„Eigenvectorï¼Œç¬¬ä¸€ä¸ªç‰¹å¾å‘é‡ä¸ºå…¨ä¸€ï¼Œæ‰€ä»¥è¦ä»ç¬¬äºŒä¸ªç‰¹å¾å‘é‡å¼€å§‹ï¼Œå³å¯å®Œæˆé™ç»´</li>
</ol>
<h2><span id="sne-and-t-sne">SNE and t-SNE</span></h2><p>ä¸»è¦æ€æƒ³æ˜¯é«˜ç»´ä¸ä½ç»´çš„åˆ†å¸ƒä¸€è‡´æˆ–è€…ç±»ä¼¼ï¼Œ</p>
<h3><span id="sne">SNE</span></h3><p>SNEæ˜¯é«˜ç»´åº¦ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒæ¥æ‹Ÿåˆï¼Œç„¶åç”¨KLæ•£åº¦æ¥ç”¨å·²çŸ¥çš„é«˜ç»´åˆ†å¸ƒå»å¾—åˆ°ä½ç»´åˆ†å¸ƒï¼Œå‰åé»˜è®¤éƒ½æ˜¯é«˜æ–¯åˆ†å¸ƒã€‚å·²çŸ¥åŸæ¥çš„é«˜ç»´åˆ†å¸ƒï¼Œç„¶ååˆå§‹åŒ–ä½ç»´æ•°æ®ï¼Œç„¶åç”¨æ¢¯åº¦ä¸‹è®²æ‹Ÿåˆã€‚</p>
<p>ä½†æ˜¯ç”±äºé«˜æ–¯åˆ†å¸ƒå¯¹outlieræ•æ„Ÿï¼Œæ‰€ä»¥SNEæ•ˆæœå¹¶ä¸å¥½ï¼Œä¼šå‡ºç°é‡å ã€‚</p>
<p>é«˜ç»´åˆ†å¸ƒï¼š</p>
<p><img src="https://github.com/PPPPan/PPPPan.github.io/blob/master/images/sne_1.JPG?raw=true"></p>
<p>ä½ç»´åˆ†å¸ƒï¼š</p>
<p><img src="https://github.com/PPPPan/PPPPan.github.io/blob/master/images/sne2.JPG?raw=true"></p>
<p>ä½¿ç”¨KLæ•£åº¦å»æ‹Ÿåˆï¼Œå¹¶ç”¨æ¢¯åº¦æœ€å°åŒ–ä¼˜åŒ–ï¼š</p>
<p><img src="https://github.com/PPPPan/PPPPan.github.io/blob/master/images/sne3.JPG?raw=true"></p>
<p><img src="https://github.com/PPPPan/PPPPan.github.io/blob/master/images/sne4.JPG?raw=true" alt="sne4.JPG"></p>
<p>ç®—æ³•æµç¨‹ï¼š</p>
<p><img src="https://github.com/PPPPan/PPPPan.github.io/blob/master/images/sne6.JPG?raw=true" alt="sne6.JPG"></p>
<h3><span id="t-sne">t-SNE</span></h3><p>t-SNEå¯ä»¥è®¤ä¸ºæ˜¯å¯¹SNEçš„ä¸€ä¸ªä¼˜åŒ–ï¼ŒåŸºæœ¬æ€æƒ³ä¸€è‡´ï¼Œéƒ½æ˜¯ç”¨ä½ç»´çš„å»æ‹Ÿåˆé«˜ç»´çš„ï¼Œåªæ˜¯ä½ç»´æ‹Ÿåˆä¸å†ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒï¼Œè€Œæ˜¯ä½¿ç”¨tåˆ†å¸ƒï¼Œå› ä¸ºtåˆ†å¸ƒå¯¹outlierè·Ÿå…·æœ‰é²æ£’æ€§ï¼Œæ‰€ä»¥æ•ˆæœæ›´å¥½ã€‚</p>
<p>ä½ç»´åˆ†å¸ƒä½¿ç”¨t-åˆ†å¸ƒï¼š</p>
<p><img src="https://github.com/PPPPan/PPPPan.github.io/blob/master/images/sne5.JPG?raw=true" alt="sne5.JPG"></p>
<p>SNEä¸»è¦ç”¨äºé«˜ç»´æ•°æ®çš„å¯è§†åŒ–ã€‚</p>
<h2><span id="cnn">CNN</span></h2><p>ä¸»è¦ç”¨äºå›¾ç‰‡å¤„ç†ï¼Œå› ä¸ºå›¾ç‰‡é€šå¸¸ç»´åº¦å¾ˆé«˜ï¼Œå¦‚æœä½¿ç”¨å¸¸è§„çš„ç½‘ç»œï¼Œä¼šä½¿å‚æ•°è¿‡å¤šï¼Œä½¿ç”¨convolutionï¼Œç”¨patternæå–ç‰¹å¾ï¼Œç„¶åå¯ä»¥ç”¨poolingè¿›ä¸€æ­¥é™ä½ç»´åº¦ã€‚</p>
<p>pooling:</p>
<ol>
<li>max poolingæˆ–è€…average pooling</li>
<li>é€šå¸¸æ¥è¯´max poolingçš„æ•ˆæœæ›´å¥½</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/ML/" rel="tag"># ML</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/04/15/Plan/" rel="prev" title="Schedule(SS2021 TUB)">
      <i class="fa fa-chevron-left"></i> Schedule(SS2021 TUB)
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/04/16/git/" rel="next" title="git-command">
      git-command <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">1.</span> <span class="nav-text">å‘é‡å’ŒçŸ©é˜µ</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">2.</span> <span class="nav-text">å‘é‡çš„èŒƒæ•°(norm)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">3.</span> <span class="nav-text">é€†çŸ©é˜µ(matrix inversion)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">4.</span> <span class="nav-text">å•ä½å‘é‡</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">5.</span> <span class="nav-text">æ­£äº¤çŸ©é˜µï¼ˆorthogonal matrixï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">6.</span> <span class="nav-text">ç‰¹å¾åˆ†è§£ï¼ˆeigendecomposition)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">7.</span> <span class="nav-text">å¥‡å¼‚å€¼åˆ†è§£ï¼ˆsingular value decomposition, SVD)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">8.</span> <span class="nav-text">è¿¹è¿ç®—</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">9.</span> <span class="nav-text">ä¸»æˆåˆ†åˆ†æï¼ˆprincipal components analysis, PCAï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">10.</span> <span class="nav-text">æ¦‚ç‡è®º</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">10.1.</span> <span class="nav-text">ä¿¡ä»»åº¦(degree of belief):</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">10.2.</span> <span class="nav-text">å½’ä¸€åŒ–ï¼ˆnormalizedï¼‰</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">10.3.</span> <span class="nav-text">ç¦»æ•£å‡åŒ€åˆ†å¸ƒï¼ˆuniform distributionï¼‰:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">10.4.</span> <span class="nav-text">æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆprobability density function):</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">10.4.1.</span> <span class="nav-text">è¿ç»­å‡åŒ€åˆ†å¸ƒ:</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">10.5.</span> <span class="nav-text">é“¾å¼æ³•åˆ™ï¼ˆchain ruleï¼‰:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">10.6.</span> <span class="nav-text">ç‹¬ç«‹æ€§ï¼ˆindependentï¼‰:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">10.7.</span> <span class="nav-text">æœŸæœ›ï¼ˆexpectationï¼‰:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">10.8.</span> <span class="nav-text">æ–¹å·®ï¼ˆvarianceï¼‰:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">10.9.</span> <span class="nav-text">åæ–¹å·®ï¼ˆcovarianceï¼‰:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">10.10.</span> <span class="nav-text">å¸¸ç”¨æ¦‚ç‡åˆ†å¸ƒ</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">11.</span> <span class="nav-text">æ•°å€¼è®¡ç®—</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">11.1.</span> <span class="nav-text">JacobiançŸ©é˜µ</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">12.</span> <span class="nav-text">Hessian çŸ©é˜µ</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">12.1.</span> <span class="nav-text">Karushâ€“Kuhnâ€“Tuckerï¼ˆKKTï¼‰</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">13.</span> <span class="nav-text">è·ç¦»é€‰æ‹©å…¬å¼</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">13.1.</span> <span class="nav-text">æ¬§å‡ é‡Œå¾—è·ç¦»</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">13.2.</span> <span class="nav-text">æ›¼å“ˆé¡¿è·ç¦»</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">14.</span> <span class="nav-text">è´å¶æ–¯å®šç†</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">15.</span> <span class="nav-text">æœ´ç´ è´å¶æ–¯(Naive Bayesian algorithm)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">15.1.</span> <span class="nav-text">æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘å¤„ç†(Laplace Smoothing)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">16.</span> <span class="nav-text">æŸå¤±å‡½æ•°(loss function)æˆ–ä»£ä»·å‡½æ•°(cost function)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">16.1.</span> <span class="nav-text">å¹³æ–¹æŸå¤±å‡½æ•°(quadratic loss function)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">16.2.</span> <span class="nav-text">ç»éªŒæŸå¤±(empirical loss) $R_{emp}$</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">16.3.</span> <span class="nav-text">Regression Loss</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">16.3.1.</span> <span class="nav-text">$l_1$ Loss &#x2F; Laplace Loss &#x2F; Absolute Loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">16.3.2.</span> <span class="nav-text">$l_2$ Loss &#x2F; Square Loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">16.3.3.</span> <span class="nav-text">Huber Loss</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">16.4.</span> <span class="nav-text">Classification Loss</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">16.4.1.</span> <span class="nav-text">Margin</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">16.4.2.</span> <span class="nav-text">Zero-one</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">17.</span> <span class="nav-text">GrammçŸ©é˜µ</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">18.</span> <span class="nav-text">Mercerâ€™s Theorem</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">19.</span> <span class="nav-text">Kernel Trick</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">20.</span> <span class="nav-text">æ°æ£®ä¸ç­‰å¼(Jensenâ€™s inequality)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">21.</span> <span class="nav-text">å‡¸å‡½æ•°</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">22.</span> <span class="nav-text">Weak Max-Min Inequality</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">23.</span> <span class="nav-text">æ¾å¼›äº’è¡¥ï¼ˆComplementary slacknessï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">24.</span> <span class="nav-text">ä¸¤å¹³è¡Œçº¿è·ç¦»å…¬å¼</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">25.</span> <span class="nav-text">PDF(Probability density function)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">26.</span> <span class="nav-text">CDF(Cumulative distribution function)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">27.</span> <span class="nav-text">PMF(probability mass function)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">28.</span> <span class="nav-text">æ³Šæ¾åˆ†å¸ƒ(Poisson distribution)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">29.</span> <span class="nav-text">Variance</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">30.</span> <span class="nav-text">ä¼¯åŠªåˆ©åˆ†å¸ƒå’ŒäºŒé¡¹åˆ†å¸ƒ</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">31.</span> <span class="nav-text">Zåˆ†å¸ƒå’ŒTåˆ†å¸ƒ</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">32.</span> <span class="nav-text">è’™ç‰¹å¡æ´›ç§¯åˆ†</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">33.</span> <span class="nav-text">åˆ¤åˆ«æ¨¡å‹å’Œç”Ÿæˆæ¨¡å‹</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">34.</span> <span class="nav-text">æå¤§ä¼¼ç„¶ä¼°è®¡(MLE)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">35.</span> <span class="nav-text">æœ€å¤§åéªŒæ¦‚ç‡ (MAP)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">36.</span> <span class="nav-text">æ³°å‹’å±•å¼€</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">37.</span> <span class="nav-text">æ¢¯åº¦ä¸‹é™æ³•</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">38.</span> <span class="nav-text">ç‰›é¡¿æ³•</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number"></span> <span class="nav-text">æœºå™¨å­¦ä¹ åŸºç¡€</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">1.</span> <span class="nav-text">æ— ç›‘ç£å­¦ä¹ ç®—æ³•ï¼ˆunsupervised learning algorithmï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">2.</span> <span class="nav-text">ç›‘ç£å­¦ä¹ ç®—æ³•ï¼ˆsupervised learning algorithm)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">3.</span> <span class="nav-text">å¼ºåŒ–å­¦ä¹ ï¼ˆrein-forcement learningï¼‰ç®—æ³•</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">4.</span> <span class="nav-text">è®¾è®¡çŸ©é˜µï¼ˆdesign matrixï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">5.</span> <span class="nav-text">è®­ç»ƒè¯¯å·®ï¼ˆtraining errorï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">6.</span> <span class="nav-text">æµ‹è¯•è¯¯å·®ï¼ˆtest errorï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">7.</span> <span class="nav-text">å¥¥å¡å§†å‰ƒåˆ€ Occamâ€™s Razor</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">8.</span> <span class="nav-text">Vapnik-Chervonenkis ç»´åº¦</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">9.</span> <span class="nav-text">è´å¶æ–¯è¯¯å·®ï¼ˆBayes errorï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">10.</span> <span class="nav-text">æ²¡æœ‰å…è´¹åˆé¤å®šç†ï¼ˆno freelunch theoremï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">11.</span> <span class="nav-text">æƒé‡è¡°å‡ï¼ˆweight decayï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">12.</span> <span class="nav-text">æ­£åˆ™åŒ–ï¼ˆregularizationï¼‰</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">12.1.</span> <span class="nav-text">Lasso Regularization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">12.2.</span> <span class="nav-text">Ridge Regularization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">12.3.</span> <span class="nav-text">ä¸ºä»€ä¹ˆLasso æ¯”Ridge æ›´ç¨€ç–ï¼Œ Ridgeæ¯”Lassoæ›´å¹³æ»‘</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">13.</span> <span class="nav-text">äº¤å‰éªŒè¯</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">14.</span> <span class="nav-text">é¢„æµ‹è¯¯å·®ï¼ˆmeasures prediction error,MSEï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">15.</span> <span class="nav-text">Underfitting, Overfitting</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">16.</span> <span class="nav-text">æ„ŸçŸ¥æœº(Perceptron)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">17.</span> <span class="nav-text">ç›‘ç£å­¦ä¹ </span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">17.1.</span> <span class="nav-text">é€»è¾‘å›å½’ï¼ˆlogistic regressionï¼‰</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">17.2.</span> <span class="nav-text">æ”¯æŒå‘é‡æœºï¼ˆsupport vector machine, SVM)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">17.3.</span> <span class="nav-text">å†³ç­–æ ‘</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">17.4.</span> <span class="nav-text">KNN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">18.</span> <span class="nav-text">K Mean ç®—æ³•</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">19.</span> <span class="nav-text">EMç®—æ³•</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">20.</span> <span class="nav-text">bootstrap é‡‡æ ·æ³•</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">21.</span> <span class="nav-text">çº¿æ€§å›å½’</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">22.</span> <span class="nav-text">éšæœºæ£®æ—</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">23.</span> <span class="nav-text">Boosting and bagging</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">24.</span> <span class="nav-text">XGBoost</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">25.</span> <span class="nav-text">Local Linear Embedding (LLE)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">26.</span> <span class="nav-text">SNE and t-SNE</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">26.1.</span> <span class="nav-text">SNE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">26.2.</span> <span class="nav-text">t-SNE</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">27.</span> <span class="nav-text">CNN</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Xinjian Pan  ğŸ‘¨ğŸ»â€ğŸ’»</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">16</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:xinjianpanstudent@gmail.com" title="E-Mail â†’ mailto:xinjianpanstudent@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xinjian Pan  ğŸ‘¨ğŸ»â€ğŸ’»</span>
</div>

<!--
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>-->

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
